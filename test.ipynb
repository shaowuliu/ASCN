{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d7a18a8-d4dd-42fc-9a37-a15efd2f0823",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/root/miniconda3/envs/python/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/root/miniconda3/envs/python/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/root/miniconda3/envs/python/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/root/miniconda3/envs/python/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/root/miniconda3/envs/python/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/root/miniconda3/envs/python/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/root/miniconda3/envs/python/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/root/miniconda3/envs/python/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/root/miniconda3/envs/python/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/root/miniconda3/envs/python/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/root/miniconda3/envs/python/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/root/miniconda3/envs/python/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kaishi 2022-06-23 16:29:03\n",
      "WARNING:tensorflow:From /root/miniconda3/envs/python/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /root/miniconda3/envs/python/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /root/miniconda3/envs/python/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /root/miniconda3/envs/python/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /root/miniconda3/envs/python/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /root/miniconda3/envs/python/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /root/miniconda3/envs/python/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /root/miniconda3/envs/python/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /root/miniconda3/envs/python/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /root/miniconda3/envs/python/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /root/miniconda3/envs/python/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From /root/miniconda3/envs/python/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From /root/miniconda3/envs/python/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /root/miniconda3/envs/python/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "build\n",
      "call\n",
      "softmax\n",
      "squash\n",
      "softmax\n",
      "squash\n",
      "softmax\n",
      "squash\n",
      "compute_output_shape\n",
      "build\n",
      "call\n",
      "softmax\n",
      "squash\n",
      "softmax\n",
      "squash\n",
      "softmax\n",
      "squash\n",
      "compute_output_shape\n",
      "build\n",
      "call\n",
      "softmax\n",
      "squash\n",
      "softmax\n",
      "squash\n",
      "softmax\n",
      "squash\n",
      "compute_output_shape\n",
      "WARNING:tensorflow:From /root/miniconda3/envs/python/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /root/miniconda3/envs/python/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /root/miniconda3/envs/python/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /root/miniconda3/envs/python/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, None, None, 1)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, None, None, 64)    640       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, None, None, 64)    256       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, None, None, 128)   73856     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, None, None, 128)   147584    \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, None, 128)         0         \n",
      "_________________________________________________________________\n",
      "capsule_1 (Capsule)          (None, 32, 16)            65536     \n",
      "_________________________________________________________________\n",
      "capsule_2 (Capsule)          (None, 32, 16)            8192      \n",
      "_________________________________________________________________\n",
      "capsule_3 (Capsule)          (None, 2, 16)             512       \n",
      "_________________________________________________________________\n",
      "lambda_1 (Lambda)            (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 333,504\n",
      "Trainable params: 333,376\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 32, 16)            0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 168,418\n",
      "Trainable params: 168,418\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import time\n",
    "\n",
    "import torch\n",
    "from keras import backend as K\n",
    "from keras.layers import Layer\n",
    "from keras import activations\n",
    "from keras import utils\n",
    "from keras.models import Model\n",
    "from keras.layers import *\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "# import keras\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import optimizers\n",
    "from keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pydicom\n",
    "import cv2\n",
    "from lungmask import mask #lung segmentation model\n",
    "import SimpleITK as sitk\n",
    "import SimpleITK as sitk\n",
    "# import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "# Set the path based on your data directory\n",
    "data_path = r'autodl-nas/covid/P019'\n",
    "# Set the cut-off probability for the classification output (Default : 0.5)\n",
    "cutoff = 0.5\n",
    "\n",
    "K.set_image_data_format('channels_last') # 彩色图像的性质一般包括：width、height、channels 选择channels_last：返回(256,256,3)\n",
    "\n",
    "def squash(x, axis=-1):\n",
    "    print(\"squash\")\n",
    "    s_squared_norm = K.sum(K.square(x), axis, keepdims=True) + K.epsilon()\n",
    "    scale = K.sqrt(s_squared_norm) / (1 + s_squared_norm)\n",
    "    return scale * x\n",
    "\n",
    "\n",
    "def softmax(x, axis=-1):\n",
    "    print(\"softmax\")\n",
    "    ex = K.exp(x - K.max(x, axis=axis, keepdims=True))\n",
    "    return ex / K.sum(ex, axis=axis, keepdims=True)\n",
    "\n",
    "\n",
    "def margin_loss(y_true, y_pred):\n",
    "    print(\"loss\")\n",
    "    lamb, margin = 0.5, 0.1\n",
    "    return K.sum((y_true * K.square(K.relu(1 - margin - y_pred)) + lamb * (\n",
    "        1 - y_true) * K.square(K.relu(y_pred - margin))), axis=-1)\n",
    "\n",
    "\n",
    "class Capsule(Layer):\n",
    "\n",
    "\n",
    "    def __init__(self,\n",
    "                 num_capsule, #32\n",
    "                 dim_capsule, #16\n",
    "                 routings=3,\n",
    "                 share_weights=True,\n",
    "                 activation='squash',\n",
    "                 **kwargs):\n",
    "        super(Capsule, self).__init__(**kwargs)\n",
    "        self.num_capsule = num_capsule\n",
    "        self.dim_capsule = dim_capsule\n",
    "        self.routings = routings\n",
    "        self.share_weights = share_weights\n",
    "        if activation == 'squash':\n",
    "            self.activation = squash\n",
    "        else:\n",
    "            self.activation = activations.get(activation)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "        'num_capsule':  self.num_capsule,\n",
    "        'dim_capsule' : self.dim_capsule,\n",
    "        'routings':  self.routings,\n",
    "        'share_weight':self.share_weights,\n",
    "\n",
    "\n",
    "\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        print(\"build\")\n",
    "        input_dim_capsule = input_shape[-1] # 116,14884,128\n",
    "        if self.share_weights:\n",
    "            self.kernel = self.add_weight(\n",
    "                name='capsule_kernel',\n",
    "                shape=(1, input_dim_capsule,\n",
    "                       self.num_capsule * self.dim_capsule),\n",
    "                # 1,128,512\n",
    "                initializer='glorot_uniform',\n",
    "                trainable=True)\n",
    "        else:\n",
    "            input_num_capsule = input_shape[-2]\n",
    "            self.kernel = self.add_weight(\n",
    "                name='capsule_kernel',\n",
    "                shape=(input_num_capsule, input_dim_capsule,\n",
    "                       self.num_capsule * self.dim_capsule),\n",
    "                initializer='glorot_uniform',\n",
    "                trainable=True)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        print(\"call\")\n",
    "\n",
    "        if self.share_weights:\n",
    "            hat_inputs = K.conv1d(inputs, self.kernel)  # 跑这个\n",
    "            # 116,14884,128  1,128,512  = 116,14884,512\n",
    "        else:\n",
    "            hat_inputs = K.local_conv1d(inputs, self.kernel, [1], [1])\n",
    "\n",
    "        batch_size = K.shape(inputs)[0]\n",
    "        input_num_capsule = K.shape(inputs)[1]\n",
    "        hat_inputs = K.reshape(hat_inputs,\n",
    "                               (batch_size, input_num_capsule,\n",
    "                                self.num_capsule, self.dim_capsule))\n",
    "        # 116,14884,32,16\n",
    "        hat_inputs = K.permute_dimensions(hat_inputs, (0, 2, 1, 3))\n",
    "        # 116,32,14884,16\n",
    "        b = K.zeros_like(hat_inputs[:, :, :, 0])\n",
    "        # 116,32,14884\n",
    "        for i in range(self.routings):\n",
    "            c = softmax(b, 1)\n",
    "            o = self.activation(keras.backend.batch_dot(c, hat_inputs, [2, 2]))\n",
    "            # o = 116,32,14884  X 116,32,14884,16 ==116,32,16\n",
    "            # 初始值乘以权重的到新的胶囊\n",
    "            if i < self.routings - 1:\n",
    "                b = keras.backend.batch_dot(o, hat_inputs, [2, 3])\n",
    "                # 权重更新 116,32,16  X  116,32,14884,16  = 116,32,14884\n",
    "                if K.backend() == 'theano':\n",
    "                    o = K.sum(o, axis=1)\n",
    "\n",
    "        return o\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        print(\"compute_output_shape\")\n",
    "        return (None, self.num_capsule, self.dim_capsule)\n",
    "\n",
    "# normalization function\n",
    "def normalize_image(x): #normalize image pixels between 0 and 1\n",
    "        if np.max(x)-np.min(x) == 0 and np.max(x) == 0:\n",
    "            return x\n",
    "        elif np.max(x)-np.min(x) == 0 and np.max(x) != 0:\n",
    "            return x/np.max(x)\n",
    "        else:\n",
    "            return (x-np.min(x))/(np.max(x)-np.min(x))\n",
    "\n",
    "\n",
    "def segment_lung(mask,model,volume_path): #mask 是 模型的得到的方法 model是unet+R321covid\n",
    "\n",
    "    # model = mask.get_model('unet','R231CovidWeb')\n",
    "    #loop through all dcm files\n",
    "    lstFilesDCM = []  # create an empty list\n",
    "    for dirName, subdirList, fileList in os.walk(volume_path):\n",
    "        for filename in fileList:\n",
    "            if \".dcm\" in filename.lower():  # check whether the file's DICOM\n",
    "                lstFilesDCM.append(os.path.join(dirName,filename))\n",
    "\n",
    "    dataset = pydicom.dcmread(lstFilesDCM[0]) # a sample image\n",
    "    slice_numbers = len(lstFilesDCM) #number of slices\n",
    "    # print('Slices:',slice_numbers)\n",
    "    #print(\"dataset\",dataset)\n",
    "    #输出dataset后，发现里面居然除了图片的信息之外还有 比如的信息\n",
    "    # (0009, 0010) Private Creator LO: 'SIEMENS CT VA1 DUMMY'\n",
    "    # (0010, 0020) Patient ID      LO: 'P169'\n",
    "    # (0010, 0040) Patient's Sex   CS: 'M'\n",
    "    # (0010, 1010) Patient's Age   AS: '075Y'\n",
    "    #(7fe0, 0010) Pixel Data   OB: Array of 262374 elements\n",
    "    if 'PixelData' in dataset:\n",
    "        rows = int(dataset.Rows)\n",
    "        cols = int(dataset.Columns)\n",
    "        # print('Image size:',rows,cols)\n",
    "\n",
    "    slice_z_locations = []\n",
    "    for filenameDCM in lstFilesDCM:\n",
    "        ds = pydicom.dcmread(filenameDCM)\n",
    "        slice_z_locations.append(ds.get('SliceLocation'))\n",
    "\n",
    "    #sorting slices based on z locations\n",
    "    slice_locations = list(zip(lstFilesDCM,slice_z_locations))\n",
    "    sorted_slice_locations = sorted(slice_locations, key = lambda x: x[1])[-1::-1]\n",
    "\n",
    "    # Saving Slices in a numpy array\n",
    "    ArrayDicom = np.zeros((slice_numbers,rows,cols)) # 这里面存的才是基础的ct的图片\n",
    "    lung_mask = np.uint8(np.zeros((slice_numbers,rows,cols))) # unit8创建图像容器\n",
    "    # 这里面存的是 这个位置是否存在肺部组织 是 --1  否  --0\n",
    "    # loop through all the DICOM files\n",
    "    i = 0\n",
    "    for filenameDCM, z_location in sorted_slice_locations:\n",
    "        # read the file\n",
    "        ds = sitk.ReadImage(filenameDCM)\n",
    "        segmentation = mask.apply(ds, model) # segmentation 0 or 1 (1, 512, 512)\n",
    "        # 这个模型只是把肺部的位置提取出来了，提取出只包含 -1 0 1的数组\n",
    "        lung_mask[i,:,:] = np.uint8(((segmentation>0)*1)[0]) #uint8是专门用于存储各种图像的（包括RGB，灰度图像等），范围是从0–255\n",
    "        # lung_mask就是把 -1 去掉，然后以图片的形式保存这个数组\n",
    "        ArrayDicom[i, :, :] = sitk.GetArrayFromImage(ds)\n",
    "        # ArrayDicom 就是 原来这个ct没见过处理的样子\n",
    "        # 可用于将SimpleITK对象转换为ndarray  就是把图像变成数组\n",
    "        # 使用GetArrayFromImage()方法后，X轴与Z轴发生了对调，输出形状为：(Depth, Height, Width)\n",
    "        i = i+1\n",
    "    # print(\"输出第一张切片的分割结果\")\n",
    "   # showpicture(lung_mask[0])\n",
    "    lungs = np.zeros((ArrayDicom.shape[0],256,256,1))\n",
    "    # resizing the data\n",
    "    for i in range(ArrayDicom.shape[0]):\n",
    "        ct = normalize_image(ArrayDicom[i,:,:])\n",
    "        mask_l = lung_mask[i,:,:]\n",
    "        seg = mask_l * ct #apply mask on the image  seg.shape (512, 512)\n",
    "        # mask_l 是分割后的肺部阴影图  ct是 每个肺部ct\n",
    "        img = cv2.resize(seg,(256,256)) # 512X512 到 256X256\n",
    "        img = normalize_image(img) #img.shape (256, 256)\n",
    "        lungs[i,:,:,:] = np.expand_dims(img,axis = -1)\n",
    "    # print('Successfully segmented.')\n",
    "    # print(lung_mask.shape,ArrayDicom.shape,lungs.shape)\n",
    "    # (121, 512, 512) (121, 512, 512) (121, 256, 256, 1)  这里就是121个dcm文件的512*512矩阵\n",
    "    # 输出代码：a[1] 第二行 a[:,1] 第二列  默认二维矩阵\n",
    "    # print(lung_mask[0]) 全是0和1\n",
    "    # print(lungs[onepic,124, 124, 0]) # 0.0\n",
    "    # expand_dims:如果设置axis为1，矩阵大小就变成了（2,1,3），变成了一个2*1*3的三维矩阵 -1 就是最后一个维度 aixs从0开始\n",
    "    return lung_mask, ArrayDicom, lungs\n",
    "\n",
    "def max_vote(x):\n",
    "    v = np.max(x, axis=0) #aixs = 0 代表 列\n",
    "    # 多个维度相比 取出切片数目个维度的每行每列最大值（我可以认为是特征最明显吗？） 这是取出最大 理解为消去 axis=0 就是从（a，b，c） 到 （b，c）\n",
    "    return v\n",
    "\n",
    "def tet_one_dicom(model,X_test):\n",
    "    X_test_normal = np.zeros(X_test.shape)\n",
    "    for i in range(X_test.shape[0]):\n",
    "        X_test_normal[i,:,:,:] = normalize_image(X_test[i,:,:,:])\n",
    "\n",
    "    # X-test 的model(121, 256, 256, 1) 121和168是不同人的切片数目\n",
    "    sum_seg = np.sum(np.sum(X_test,axis=1),axis=1) #(168, 1) 算是综合出来判断这个部位有没有信息 to find out if lung exists or not\n",
    "    # 当加入axis=1以后就是将一个矩阵的每一行向量相加\n",
    "    a = np.where(sum_seg[:,0] != 0)\n",
    "    # 这个就是显示之前判断的有肺部部位的数据的地址（168，1） 【0，0，0，4，5，6.。。。】这种的内容  找出了不能用的切片吗？\n",
    "    # where现在没有x和y了,最终结果返回的就是判断结果为true的元素所在的位置信息.\n",
    "    X_test = X_test_normal[a]\n",
    "\n",
    "    capsules = np.zeros((1,32,16))\n",
    "    # print(\"得出的特征图的灰度图\")\n",
    "    #wpicture(capsules[0])\n",
    "    if len(X_test_normal)==0:\n",
    "        capsules[0] = np.zeros((32,16))-1\n",
    "    else:\n",
    "        x_capsule = model.predict(X_test)\n",
    "        #  输入第一个模型的X_test.shape (152, 256, 256, 1) 这个152原来是切片数量168，但是前面判断存在16个空的部位，所有只剩下152个\n",
    "        # 所有的切片都送到了\n",
    "\n",
    "        # print(\"x_capsule.shape\",x_capsule.shape) # 模型预测的结果x_capsule.shape (116, 32, 16)\n",
    "        capsules[0] = max_vote(x_capsule) # [32,16] 我觉得又问题\n",
    "        plt.imshow(max_vote(x_capsule))\n",
    "        plt.show\n",
    "    # print(\"capsules.shape\",capsules.shape) #[1,32,16]\n",
    "    return capsules\n",
    "\n",
    "def stage_two_output(x_test,model2,cutoff):\n",
    "    pred = model2.predict(x_test)  # pred (1, 2) 输入第二个模型x_test.shape (1, 32, 16)\n",
    "    prob_one = pred[:, 1]  # prob_one [1.] 代码中的那个\n",
    "    prob_to=pred[:, 0]\n",
    "    pred_final = (prob_one>= cutoff)*1  # cut-off probability\n",
    "    # print(\"prob_one,prob_tow\",prob_one,prob_tow)\n",
    "    print(\"另一个,代码中那个\", prob_to, prob_one)  # prob_one.shape (1,) (x,)意思是一维数组，数组中有2个元素\n",
    "    return prob_one, pred_final\n",
    "\n",
    "# def showpicture(a):\n",
    "#     image = Image.open(a)\n",
    "#     mat = np.array(image)\n",
    "#     plt.imshow(mat)\n",
    "#     plt.show()\n",
    "\n",
    "print(\"kaishi\",time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime()))\n",
    "#%% Model1 (Feature Extractor)\n",
    "\n",
    "input_image = Input(shape=(None, None, 1))\n",
    "#  输入的大小是(116, 256, 256, 1)\n",
    "x = Conv2D(64, (3, 3), activation='relu',trainable = True)(input_image)\n",
    "#  卷积一下(116, 254, 254, 64)\n",
    "x = BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, beta_constraint=None, gamma_constraint=None)(x)\n",
    "#   batch之后(116, 254, 254, 64)\n",
    "x = Conv2D(64, (3, 3), activation='relu',trainable = True)(x)\n",
    "#   第二次卷积 (116, 252, 252, 64)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "#   最大池化(116, 126, 126, 64)\n",
    "x = Conv2D(128, (3, 3), activation='relu',trainable = True)(x)\n",
    "#   再卷积一次(116, 124, 124, 128)\n",
    "x = Conv2D(128, (3, 3), activation='relu',trainable = True)(x)\n",
    "#   (116, 122, 122, 128)  先不看116这个数   变成了 122x122x128\n",
    "x = Reshape((-1, 128))(x)\n",
    "#   不知行数，分成128列 输出x_capsule.shape (116, 14884, 128)  为什么显示出来的是（？，？，128）这个14884为什么不显示呢？\n",
    "#   把16个特征图展开成为一维  所以应该是 14884x8的高,16的底的长方形 然后合并成 14884x8个胶囊,每个胶囊维度为16\n",
    "x = Capsule(32, 16, 3, True)(x)\n",
    "#  (116, 32, 16) 1行就是一个胶囊  16维胶囊  32个胶囊\n",
    "x = Capsule(32, 16, 3, True)(x)\n",
    "# output 是 (116, 32, 16)\n",
    "capsule = Capsule(2, 16, 3, True)(x)\n",
    "# 输出是(116, 2, 16)\n",
    "output = Lambda(lambda z: K.sqrt(K.sum(K.square(z), 2)))(capsule) # (116,2)\n",
    "#  上面这不算是一层网络\n",
    "model = Model(inputs=[input_image], outputs=[output])\n",
    "\n",
    "\n",
    "adam = optimizers.Adam(lr=1e-4)\n",
    "model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "# model.save_weights(\"model.h5\")\n",
    "model.load_weights('weights-2class-v1-71.h5')\n",
    "model.summary()\n",
    "\n",
    "#\n",
    "input_stage_fe = model.input\n",
    "output_stage_fe = model.layers[-3].output\n",
    "\n",
    "model_fe = Model(input_stage_fe,output_stage_fe)\n",
    "\n",
    "#%% Model2 (Final Patient-Level Classifier)\n",
    "\n",
    "input_tensor = Input(shape=(32,16))\n",
    "# (?, 32, 16)\n",
    "# (?, ?)\n",
    "# (?, 256)\n",
    "# (?, 128)\n",
    "# (?, 32)\n",
    "# (?, 2)\n",
    "x2 = Flatten()(input_tensor)\n",
    "\n",
    "x2 = Dense(256,activation = 'relu')(x2)\n",
    "x2 = Dense(128,activation = 'relu')(x2)\n",
    "x2 = Dense(32,activation = 'relu')(x2)\n",
    "out2 = Dense(2, activation = 'softmax')(x2)\n",
    "\n",
    "model2 = Model(input_tensor,out2)\n",
    "#opt = optimizers.Adam(lr=0.001)\n",
    "#model2.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=['accuracy']) #adadelta\n",
    "#model2.save_weights(\"cap.h5\")\n",
    "\n",
    "model2.load_weights('binary-max-v4.h5')  # 对于covid169 covid的概率为0.00089189\n",
    "#model2.load_weights('cap.h5')  #对于covid169 covid的概率为0.4\n",
    "model2.summary()\n",
    "\n",
    "\n",
    "#%%\n",
    "model_sg = mask.get_model('unet','R231CovidWeb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d784bcf-1e5f-4769-b44f-f2e3c54ddf68",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred =[]\n",
    "# test = np.load(\"../autodl-tmp/capsuleall3216/cap/capmap44.npy\")\n",
    "\n",
    "# tests = np.zeros(shape=(1,32,16))\n",
    "# tests[0] =np.max(test,0)\n",
    "for i in range(10,100):\n",
    "    data_path = '../autodl-tmp/Covid Cases/covid0'+str(i)\n",
    "    print('Segmenting lung area...')\n",
    "    lung_mask, ArrayDicom, lung = segment_lung(mask,model_sg,data_path)\n",
    "    print('Segmentation is Completed.')\n",
    "\n",
    "    capsules = tet_one_dicom(model_fe,lung)\n",
    "\n",
    "\n",
    "    # Stage 2 下面是病患级别的\n",
    "    prob_one, pred_final = stage_two_output(capsules,model2,cutoff)\n",
    "    if pred_final ==1 :\n",
    "        prediction = 'COVID-19'\n",
    "        pred.append(data_path)\n",
    "    else:\n",
    "        prediction = 'non-COVID'\n",
    "\n",
    "    print('prediction: ',prediction)\n",
    "    print(\"true:\",data_path)\n",
    "    print(\"jieshu\",time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime()))\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7c5a7a-d8b5-4ee3-9802-7d5abf1ef9b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python]",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
