{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c55b4e8b-d8ee-4b48-9981-1352b12befad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         (None, 32, 16)            0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 168,418\n",
      "Trainable params: 168,418\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 274 samples, validate on 31 samples\n",
      "Epoch 1/500\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.5749 - acc: 0.7956 - val_loss: 0.3639 - val_acc: 0.9032\n",
      "Epoch 2/500\n",
      "274/274 [==============================] - 0s 386us/step - loss: 0.3812 - acc: 0.8394 - val_loss: 0.0286 - val_acc: 1.0000\n",
      "Epoch 3/500\n",
      "274/274 [==============================] - 0s 395us/step - loss: 0.3934 - acc: 0.8066 - val_loss: 0.1202 - val_acc: 0.9677\n",
      "Epoch 4/500\n",
      "274/274 [==============================] - 0s 374us/step - loss: 0.3495 - acc: 0.8504 - val_loss: 0.0669 - val_acc: 1.0000\n",
      "Epoch 5/500\n",
      "274/274 [==============================] - 0s 393us/step - loss: 0.3403 - acc: 0.8577 - val_loss: 0.0527 - val_acc: 1.0000\n",
      "Epoch 6/500\n",
      "274/274 [==============================] - 0s 443us/step - loss: 0.3312 - acc: 0.8613 - val_loss: 0.0472 - val_acc: 1.0000\n",
      "Epoch 7/500\n",
      "274/274 [==============================] - 0s 369us/step - loss: 0.3273 - acc: 0.8540 - val_loss: 0.0143 - val_acc: 1.0000\n",
      "Epoch 8/500\n",
      "274/274 [==============================] - 0s 406us/step - loss: 0.3683 - acc: 0.8358 - val_loss: 0.0961 - val_acc: 1.0000\n",
      "Epoch 9/500\n",
      "274/274 [==============================] - 0s 402us/step - loss: 0.3532 - acc: 0.8504 - val_loss: 0.0720 - val_acc: 1.0000\n",
      "Epoch 10/500\n",
      "274/274 [==============================] - 0s 404us/step - loss: 0.3345 - acc: 0.8467 - val_loss: 0.0351 - val_acc: 1.0000\n",
      "Epoch 11/500\n",
      "274/274 [==============================] - 0s 416us/step - loss: 0.3280 - acc: 0.8431 - val_loss: 0.1087 - val_acc: 0.9677\n",
      "Epoch 12/500\n",
      "274/274 [==============================] - 0s 446us/step - loss: 0.3534 - acc: 0.8613 - val_loss: 0.0661 - val_acc: 1.0000\n",
      "Epoch 13/500\n",
      "274/274 [==============================] - 0s 388us/step - loss: 0.3312 - acc: 0.8394 - val_loss: 0.0216 - val_acc: 1.0000\n",
      "Epoch 14/500\n",
      "274/274 [==============================] - 0s 408us/step - loss: 0.3285 - acc: 0.8686 - val_loss: 0.0969 - val_acc: 1.0000\n",
      "Epoch 15/500\n",
      "274/274 [==============================] - 0s 372us/step - loss: 0.3420 - acc: 0.8650 - val_loss: 0.0511 - val_acc: 1.0000\n",
      "Epoch 16/500\n",
      "274/274 [==============================] - 0s 368us/step - loss: 0.3259 - acc: 0.8686 - val_loss: 0.0767 - val_acc: 1.0000\n",
      "Epoch 17/500\n",
      "274/274 [==============================] - 0s 427us/step - loss: 0.3302 - acc: 0.8540 - val_loss: 0.0757 - val_acc: 1.0000\n",
      "Epoch 18/500\n",
      "274/274 [==============================] - 0s 389us/step - loss: 0.3307 - acc: 0.8467 - val_loss: 0.0354 - val_acc: 1.0000\n",
      "Epoch 19/500\n",
      "274/274 [==============================] - 0s 465us/step - loss: 0.3252 - acc: 0.8504 - val_loss: 0.0332 - val_acc: 1.0000\n",
      "Epoch 20/500\n",
      "274/274 [==============================] - 0s 462us/step - loss: 0.3295 - acc: 0.8431 - val_loss: 0.1834 - val_acc: 0.9032\n",
      "Epoch 21/500\n",
      "274/274 [==============================] - 0s 404us/step - loss: 0.3467 - acc: 0.8358 - val_loss: 0.0362 - val_acc: 1.0000\n",
      "Epoch 22/500\n",
      "274/274 [==============================] - 0s 454us/step - loss: 0.3275 - acc: 0.8613 - val_loss: 0.0847 - val_acc: 1.0000\n",
      "Epoch 23/500\n",
      "274/274 [==============================] - 0s 507us/step - loss: 0.3278 - acc: 0.8467 - val_loss: 0.0368 - val_acc: 1.0000\n",
      "Epoch 24/500\n",
      "274/274 [==============================] - 0s 353us/step - loss: 0.3270 - acc: 0.8504 - val_loss: 0.0313 - val_acc: 1.0000\n",
      "Epoch 25/500\n",
      "274/274 [==============================] - 0s 408us/step - loss: 0.3279 - acc: 0.8540 - val_loss: 0.0541 - val_acc: 1.0000\n",
      "Epoch 26/500\n",
      "274/274 [==============================] - 0s 376us/step - loss: 0.3304 - acc: 0.8577 - val_loss: 0.0923 - val_acc: 1.0000\n",
      "Epoch 27/500\n",
      "274/274 [==============================] - 0s 439us/step - loss: 0.3359 - acc: 0.8431 - val_loss: 0.0792 - val_acc: 1.0000\n",
      "Epoch 28/500\n",
      "274/274 [==============================] - 0s 436us/step - loss: 0.3265 - acc: 0.8540 - val_loss: 0.0165 - val_acc: 1.0000\n",
      "Epoch 29/500\n",
      "274/274 [==============================] - 0s 397us/step - loss: 0.3485 - acc: 0.8431 - val_loss: 0.1708 - val_acc: 0.9032\n",
      "Epoch 30/500\n",
      "274/274 [==============================] - 0s 372us/step - loss: 0.3289 - acc: 0.8504 - val_loss: 0.0539 - val_acc: 1.0000\n",
      "Epoch 31/500\n",
      "274/274 [==============================] - 0s 385us/step - loss: 0.3202 - acc: 0.8650 - val_loss: 0.0793 - val_acc: 1.0000\n",
      "Epoch 32/500\n",
      "274/274 [==============================] - 0s 386us/step - loss: 0.3165 - acc: 0.8759 - val_loss: 0.0466 - val_acc: 1.0000\n",
      "Epoch 33/500\n",
      "274/274 [==============================] - 0s 388us/step - loss: 0.3087 - acc: 0.8650 - val_loss: 0.0585 - val_acc: 1.0000\n",
      "Epoch 34/500\n",
      "274/274 [==============================] - 0s 381us/step - loss: 0.3091 - acc: 0.8686 - val_loss: 0.0630 - val_acc: 1.0000\n",
      "Epoch 35/500\n",
      "274/274 [==============================] - 0s 404us/step - loss: 0.3075 - acc: 0.8686 - val_loss: 0.0518 - val_acc: 1.0000\n",
      "Epoch 36/500\n",
      "274/274 [==============================] - 0s 365us/step - loss: 0.3078 - acc: 0.8723 - val_loss: 0.0558 - val_acc: 1.0000\n",
      "Epoch 37/500\n",
      "274/274 [==============================] - 0s 389us/step - loss: 0.3083 - acc: 0.8650 - val_loss: 0.0368 - val_acc: 1.0000\n",
      "Epoch 38/500\n",
      "274/274 [==============================] - 0s 368us/step - loss: 0.3087 - acc: 0.8540 - val_loss: 0.0794 - val_acc: 1.0000\n",
      "Epoch 39/500\n",
      "274/274 [==============================] - 0s 368us/step - loss: 0.3271 - acc: 0.8613 - val_loss: 0.0495 - val_acc: 1.0000\n",
      "Epoch 40/500\n",
      "274/274 [==============================] - 0s 405us/step - loss: 0.3020 - acc: 0.8759 - val_loss: 0.0876 - val_acc: 1.0000\n",
      "Epoch 41/500\n",
      "274/274 [==============================] - 0s 380us/step - loss: 0.3086 - acc: 0.8540 - val_loss: 0.0433 - val_acc: 1.0000\n",
      "Epoch 42/500\n",
      "274/274 [==============================] - 0s 400us/step - loss: 0.3037 - acc: 0.8686 - val_loss: 0.0520 - val_acc: 1.0000\n",
      "Epoch 43/500\n",
      "274/274 [==============================] - 0s 367us/step - loss: 0.3117 - acc: 0.8504 - val_loss: 0.0930 - val_acc: 1.0000\n",
      "Epoch 44/500\n",
      "274/274 [==============================] - 0s 389us/step - loss: 0.3020 - acc: 0.8650 - val_loss: 0.0517 - val_acc: 1.0000\n",
      "Epoch 45/500\n",
      "274/274 [==============================] - 0s 378us/step - loss: 0.2970 - acc: 0.8650 - val_loss: 0.0512 - val_acc: 1.0000\n",
      "Epoch 46/500\n",
      "274/274 [==============================] - 0s 369us/step - loss: 0.3136 - acc: 0.8650 - val_loss: 0.1058 - val_acc: 1.0000\n",
      "Epoch 47/500\n",
      "274/274 [==============================] - 0s 359us/step - loss: 0.3565 - acc: 0.8321 - val_loss: 0.0839 - val_acc: 1.0000\n",
      "Epoch 48/500\n",
      "274/274 [==============================] - 0s 376us/step - loss: 0.3488 - acc: 0.8358 - val_loss: 0.1578 - val_acc: 1.0000\n",
      "Epoch 49/500\n",
      "274/274 [==============================] - 0s 383us/step - loss: 0.3124 - acc: 0.8759 - val_loss: 0.0511 - val_acc: 1.0000\n",
      "Epoch 50/500\n",
      "274/274 [==============================] - 0s 410us/step - loss: 0.3030 - acc: 0.8613 - val_loss: 0.0843 - val_acc: 1.0000\n",
      "Epoch 51/500\n",
      "274/274 [==============================] - 0s 376us/step - loss: 0.2972 - acc: 0.8723 - val_loss: 0.0745 - val_acc: 1.0000\n",
      "Epoch 52/500\n",
      "274/274 [==============================] - 0s 369us/step - loss: 0.3147 - acc: 0.8467 - val_loss: 0.0542 - val_acc: 1.0000\n",
      "Epoch 53/500\n",
      "274/274 [==============================] - 0s 389us/step - loss: 0.3025 - acc: 0.8467 - val_loss: 0.0818 - val_acc: 1.0000\n",
      "Epoch 54/500\n",
      "274/274 [==============================] - 0s 374us/step - loss: 0.3141 - acc: 0.8613 - val_loss: 0.0929 - val_acc: 1.0000\n",
      "Epoch 55/500\n",
      "274/274 [==============================] - 0s 368us/step - loss: 0.2924 - acc: 0.8723 - val_loss: 0.0619 - val_acc: 1.0000\n",
      "Epoch 56/500\n",
      "274/274 [==============================] - 0s 345us/step - loss: 0.2938 - acc: 0.8686 - val_loss: 0.0599 - val_acc: 1.0000\n",
      "Epoch 57/500\n",
      "274/274 [==============================] - 0s 466us/step - loss: 0.2920 - acc: 0.8613 - val_loss: 0.0499 - val_acc: 1.0000\n",
      "Epoch 58/500\n",
      "274/274 [==============================] - 0s 477us/step - loss: 0.3130 - acc: 0.8686 - val_loss: 0.0816 - val_acc: 1.0000\n",
      "Epoch 59/500\n",
      "274/274 [==============================] - 0s 389us/step - loss: 0.2901 - acc: 0.8686 - val_loss: 0.0565 - val_acc: 1.0000\n",
      "Epoch 60/500\n",
      "274/274 [==============================] - 0s 368us/step - loss: 0.2867 - acc: 0.8686 - val_loss: 0.0691 - val_acc: 1.0000\n",
      "Epoch 61/500\n",
      "274/274 [==============================] - 0s 361us/step - loss: 0.2851 - acc: 0.8686 - val_loss: 0.0681 - val_acc: 1.0000\n",
      "Epoch 62/500\n",
      "274/274 [==============================] - 0s 369us/step - loss: 0.2891 - acc: 0.8650 - val_loss: 0.0468 - val_acc: 1.0000\n",
      "Epoch 63/500\n",
      "274/274 [==============================] - 0s 410us/step - loss: 0.2942 - acc: 0.8504 - val_loss: 0.1454 - val_acc: 0.9355\n",
      "Epoch 64/500\n",
      "274/274 [==============================] - 0s 388us/step - loss: 0.3047 - acc: 0.8540 - val_loss: 0.0617 - val_acc: 1.0000\n",
      "Epoch 65/500\n",
      "274/274 [==============================] - 0s 376us/step - loss: 0.3080 - acc: 0.8540 - val_loss: 0.0901 - val_acc: 1.0000\n",
      "Epoch 66/500\n",
      "274/274 [==============================] - 0s 362us/step - loss: 0.3194 - acc: 0.8431 - val_loss: 0.0558 - val_acc: 1.0000\n",
      "Epoch 67/500\n",
      "274/274 [==============================] - 0s 374us/step - loss: 0.2874 - acc: 0.8723 - val_loss: 0.0722 - val_acc: 1.0000\n",
      "Epoch 68/500\n",
      "274/274 [==============================] - 0s 418us/step - loss: 0.2884 - acc: 0.8650 - val_loss: 0.0716 - val_acc: 1.0000\n",
      "Epoch 69/500\n",
      "274/274 [==============================] - 0s 415us/step - loss: 0.2934 - acc: 0.8577 - val_loss: 0.0559 - val_acc: 1.0000\n",
      "Epoch 70/500\n",
      "274/274 [==============================] - 0s 395us/step - loss: 0.2877 - acc: 0.8796 - val_loss: 0.0739 - val_acc: 1.0000\n",
      "Epoch 71/500\n",
      "274/274 [==============================] - 0s 377us/step - loss: 0.2835 - acc: 0.8723 - val_loss: 0.0587 - val_acc: 1.0000\n",
      "Epoch 72/500\n",
      "274/274 [==============================] - 0s 377us/step - loss: 0.2814 - acc: 0.8759 - val_loss: 0.0694 - val_acc: 1.0000\n",
      "Epoch 73/500\n",
      "274/274 [==============================] - 0s 403us/step - loss: 0.2789 - acc: 0.8759 - val_loss: 0.0591 - val_acc: 1.0000\n",
      "Epoch 74/500\n",
      "274/274 [==============================] - 0s 360us/step - loss: 0.2967 - acc: 0.8577 - val_loss: 0.0524 - val_acc: 1.0000\n",
      "Epoch 75/500\n",
      "274/274 [==============================] - 0s 374us/step - loss: 0.2922 - acc: 0.8686 - val_loss: 0.0690 - val_acc: 1.0000\n",
      "Epoch 76/500\n",
      "274/274 [==============================] - 0s 361us/step - loss: 0.2932 - acc: 0.8613 - val_loss: 0.0663 - val_acc: 1.0000\n",
      "Epoch 77/500\n",
      "274/274 [==============================] - 0s 361us/step - loss: 0.2750 - acc: 0.8723 - val_loss: 0.0696 - val_acc: 1.0000\n",
      "Epoch 78/500\n",
      "274/274 [==============================] - 0s 395us/step - loss: 0.2763 - acc: 0.8759 - val_loss: 0.0728 - val_acc: 1.0000\n",
      "Epoch 79/500\n",
      "274/274 [==============================] - 0s 356us/step - loss: 0.2748 - acc: 0.8723 - val_loss: 0.0458 - val_acc: 1.0000\n",
      "Epoch 80/500\n",
      "274/274 [==============================] - 0s 360us/step - loss: 0.2850 - acc: 0.8759 - val_loss: 0.0555 - val_acc: 1.0000\n",
      "Epoch 81/500\n",
      "274/274 [==============================] - 0s 405us/step - loss: 0.3437 - acc: 0.8613 - val_loss: 0.1402 - val_acc: 0.9032\n",
      "Epoch 82/500\n",
      "274/274 [==============================] - 0s 381us/step - loss: 0.3119 - acc: 0.8650 - val_loss: 0.0831 - val_acc: 1.0000\n",
      "Epoch 83/500\n",
      "274/274 [==============================] - 0s 377us/step - loss: 0.2864 - acc: 0.8650 - val_loss: 0.0628 - val_acc: 1.0000\n",
      "Epoch 84/500\n",
      "274/274 [==============================] - 0s 403us/step - loss: 0.2727 - acc: 0.8796 - val_loss: 0.0519 - val_acc: 1.0000\n",
      "Epoch 85/500\n",
      "274/274 [==============================] - 0s 347us/step - loss: 0.3047 - acc: 0.8723 - val_loss: 0.0714 - val_acc: 1.0000\n",
      "Epoch 86/500\n",
      "274/274 [==============================] - 0s 362us/step - loss: 0.2717 - acc: 0.8832 - val_loss: 0.0710 - val_acc: 1.0000\n",
      "Epoch 87/500\n",
      "274/274 [==============================] - 0s 386us/step - loss: 0.2789 - acc: 0.8723 - val_loss: 0.0629 - val_acc: 1.0000\n",
      "Epoch 88/500\n",
      "274/274 [==============================] - 0s 363us/step - loss: 0.2796 - acc: 0.8832 - val_loss: 0.0726 - val_acc: 1.0000\n",
      "Epoch 89/500\n",
      "274/274 [==============================] - 0s 387us/step - loss: 0.2708 - acc: 0.8796 - val_loss: 0.0823 - val_acc: 1.0000\n",
      "Epoch 90/500\n",
      "274/274 [==============================] - 0s 420us/step - loss: 0.2683 - acc: 0.8723 - val_loss: 0.0668 - val_acc: 1.0000\n",
      "Epoch 91/500\n",
      "274/274 [==============================] - 0s 374us/step - loss: 0.2745 - acc: 0.8832 - val_loss: 0.0721 - val_acc: 1.0000\n",
      "Epoch 92/500\n",
      "274/274 [==============================] - 0s 342us/step - loss: 0.2737 - acc: 0.8905 - val_loss: 0.0978 - val_acc: 1.0000\n",
      "Epoch 93/500\n",
      "274/274 [==============================] - 0s 356us/step - loss: 0.2722 - acc: 0.8905 - val_loss: 0.0722 - val_acc: 1.0000\n",
      "Epoch 94/500\n",
      "274/274 [==============================] - 0s 367us/step - loss: 0.2924 - acc: 0.8613 - val_loss: 0.0706 - val_acc: 1.0000\n",
      "Epoch 95/500\n",
      "274/274 [==============================] - 0s 372us/step - loss: 0.2695 - acc: 0.8832 - val_loss: 0.0785 - val_acc: 1.0000\n",
      "Epoch 96/500\n",
      "274/274 [==============================] - 0s 372us/step - loss: 0.2654 - acc: 0.8832 - val_loss: 0.0849 - val_acc: 1.0000\n",
      "Epoch 97/500\n",
      "274/274 [==============================] - 0s 361us/step - loss: 0.2583 - acc: 0.8832 - val_loss: 0.1025 - val_acc: 0.9677\n",
      "Epoch 98/500\n",
      "274/274 [==============================] - 0s 391us/step - loss: 0.2931 - acc: 0.8759 - val_loss: 0.0687 - val_acc: 1.0000\n",
      "Epoch 99/500\n",
      "274/274 [==============================] - 0s 387us/step - loss: 0.2605 - acc: 0.8905 - val_loss: 0.0465 - val_acc: 1.0000\n",
      "Epoch 100/500\n",
      "274/274 [==============================] - 0s 395us/step - loss: 0.2714 - acc: 0.8832 - val_loss: 0.0657 - val_acc: 1.0000\n",
      "Epoch 101/500\n",
      "274/274 [==============================] - 0s 429us/step - loss: 0.2724 - acc: 0.8759 - val_loss: 0.1045 - val_acc: 1.0000\n",
      "Epoch 102/500\n",
      "274/274 [==============================] - 0s 395us/step - loss: 0.2513 - acc: 0.8942 - val_loss: 0.0667 - val_acc: 1.0000\n",
      "Epoch 103/500\n",
      "274/274 [==============================] - 0s 376us/step - loss: 0.2519 - acc: 0.8832 - val_loss: 0.0673 - val_acc: 1.0000\n",
      "Epoch 104/500\n",
      "274/274 [==============================] - 0s 406us/step - loss: 0.2655 - acc: 0.8723 - val_loss: 0.0884 - val_acc: 1.0000\n",
      "Epoch 105/500\n",
      "274/274 [==============================] - 0s 382us/step - loss: 0.2644 - acc: 0.8832 - val_loss: 0.0677 - val_acc: 1.0000\n",
      "Epoch 106/500\n",
      "274/274 [==============================] - 0s 415us/step - loss: 0.2719 - acc: 0.8723 - val_loss: 0.0821 - val_acc: 1.0000\n",
      "Epoch 107/500\n",
      "274/274 [==============================] - 0s 381us/step - loss: 0.2635 - acc: 0.8869 - val_loss: 0.0848 - val_acc: 0.9677\n",
      "Epoch 108/500\n",
      "274/274 [==============================] - 0s 360us/step - loss: 0.2531 - acc: 0.8869 - val_loss: 0.0825 - val_acc: 1.0000\n",
      "Epoch 109/500\n",
      "274/274 [==============================] - 0s 371us/step - loss: 0.2608 - acc: 0.8942 - val_loss: 0.0956 - val_acc: 0.9677\n",
      "Epoch 110/500\n",
      "274/274 [==============================] - 0s 377us/step - loss: 0.2636 - acc: 0.8978 - val_loss: 0.1250 - val_acc: 0.9032\n",
      "Epoch 111/500\n",
      "274/274 [==============================] - 0s 434us/step - loss: 0.2744 - acc: 0.8832 - val_loss: 0.1556 - val_acc: 0.9032\n",
      "Epoch 112/500\n",
      "274/274 [==============================] - 0s 435us/step - loss: 0.2425 - acc: 0.8759 - val_loss: 0.1160 - val_acc: 0.9032\n",
      "Epoch 113/500\n",
      "274/274 [==============================] - 0s 382us/step - loss: 0.2478 - acc: 0.8978 - val_loss: 0.1588 - val_acc: 0.9032\n",
      "Epoch 114/500\n",
      "274/274 [==============================] - 0s 383us/step - loss: 0.2537 - acc: 0.8942 - val_loss: 0.1659 - val_acc: 0.9032\n",
      "Epoch 115/500\n",
      "274/274 [==============================] - 0s 343us/step - loss: 0.2551 - acc: 0.8759 - val_loss: 0.1231 - val_acc: 0.9032\n",
      "Epoch 116/500\n",
      "274/274 [==============================] - 0s 376us/step - loss: 0.2327 - acc: 0.9051 - val_loss: 0.1198 - val_acc: 0.9032\n",
      "Epoch 117/500\n",
      "274/274 [==============================] - 0s 395us/step - loss: 0.2325 - acc: 0.9124 - val_loss: 0.1520 - val_acc: 0.9032\n",
      "Epoch 118/500\n",
      "274/274 [==============================] - 0s 388us/step - loss: 0.2309 - acc: 0.9051 - val_loss: 0.0484 - val_acc: 0.9677\n",
      "Epoch 119/500\n",
      "274/274 [==============================] - 0s 391us/step - loss: 0.2651 - acc: 0.8796 - val_loss: 0.3833 - val_acc: 0.7419\n",
      "Epoch 120/500\n",
      "274/274 [==============================] - 0s 348us/step - loss: 0.2682 - acc: 0.8832 - val_loss: 0.1093 - val_acc: 0.9032\n",
      "Epoch 121/500\n",
      "274/274 [==============================] - 0s 369us/step - loss: 0.2256 - acc: 0.9051 - val_loss: 0.1319 - val_acc: 0.9032\n",
      "Epoch 122/500\n",
      "274/274 [==============================] - 0s 403us/step - loss: 0.2902 - acc: 0.8723 - val_loss: 0.1078 - val_acc: 0.9032\n",
      "Epoch 123/500\n",
      "274/274 [==============================] - 0s 500us/step - loss: 0.2881 - acc: 0.8796 - val_loss: 0.0893 - val_acc: 0.9677\n",
      "Epoch 124/500\n",
      "274/274 [==============================] - 0s 408us/step - loss: 0.2582 - acc: 0.8978 - val_loss: 0.0588 - val_acc: 1.0000\n",
      "Epoch 125/500\n",
      "274/274 [==============================] - 0s 440us/step - loss: 0.2538 - acc: 0.8832 - val_loss: 0.0608 - val_acc: 1.0000\n",
      "Epoch 126/500\n",
      "274/274 [==============================] - 0s 391us/step - loss: 0.2489 - acc: 0.8796 - val_loss: 0.1020 - val_acc: 0.9032\n",
      "Epoch 127/500\n",
      "274/274 [==============================] - 0s 393us/step - loss: 0.2493 - acc: 0.8978 - val_loss: 0.0924 - val_acc: 0.9677\n",
      "Epoch 128/500\n",
      "274/274 [==============================] - 0s 419us/step - loss: 0.2434 - acc: 0.8978 - val_loss: 0.0957 - val_acc: 0.9032\n",
      "Epoch 129/500\n",
      "274/274 [==============================] - 0s 372us/step - loss: 0.2314 - acc: 0.8905 - val_loss: 0.1314 - val_acc: 0.9032\n",
      "Epoch 130/500\n",
      "274/274 [==============================] - 0s 358us/step - loss: 0.2289 - acc: 0.8978 - val_loss: 0.1000 - val_acc: 0.9032\n",
      "Epoch 131/500\n",
      "274/274 [==============================] - 0s 334us/step - loss: 0.2498 - acc: 0.8759 - val_loss: 0.1936 - val_acc: 0.8710\n",
      "Epoch 132/500\n",
      "274/274 [==============================] - 0s 461us/step - loss: 0.3036 - acc: 0.8650 - val_loss: 0.1883 - val_acc: 0.8710\n",
      "Epoch 133/500\n",
      "274/274 [==============================] - 0s 411us/step - loss: 0.2822 - acc: 0.8869 - val_loss: 0.1036 - val_acc: 0.9032\n",
      "Epoch 134/500\n",
      "274/274 [==============================] - 0s 455us/step - loss: 0.2498 - acc: 0.8905 - val_loss: 0.0670 - val_acc: 1.0000\n",
      "Epoch 135/500\n",
      "274/274 [==============================] - 0s 431us/step - loss: 0.2276 - acc: 0.9051 - val_loss: 0.0864 - val_acc: 0.9677\n",
      "Epoch 136/500\n",
      "274/274 [==============================] - 0s 457us/step - loss: 0.2396 - acc: 0.9015 - val_loss: 0.1998 - val_acc: 0.8710\n",
      "Epoch 137/500\n",
      "274/274 [==============================] - 0s 433us/step - loss: 0.2909 - acc: 0.8650 - val_loss: 0.1145 - val_acc: 0.9032\n",
      "Epoch 138/500\n",
      "274/274 [==============================] - 0s 372us/step - loss: 0.2566 - acc: 0.8869 - val_loss: 0.0817 - val_acc: 0.9677\n",
      "Epoch 139/500\n",
      "274/274 [==============================] - 0s 359us/step - loss: 0.2286 - acc: 0.9015 - val_loss: 0.0923 - val_acc: 0.9677\n",
      "Epoch 140/500\n",
      "274/274 [==============================] - 0s 380us/step - loss: 0.2158 - acc: 0.9124 - val_loss: 0.0703 - val_acc: 1.0000\n",
      "Epoch 141/500\n",
      "274/274 [==============================] - 0s 363us/step - loss: 0.2406 - acc: 0.8905 - val_loss: 0.0784 - val_acc: 0.9677\n",
      "Epoch 142/500\n",
      "274/274 [==============================] - 0s 353us/step - loss: 0.2302 - acc: 0.9124 - val_loss: 0.1137 - val_acc: 0.9032\n",
      "Epoch 143/500\n",
      "274/274 [==============================] - 0s 359us/step - loss: 0.2245 - acc: 0.8942 - val_loss: 0.1251 - val_acc: 0.9032\n",
      "Epoch 144/500\n",
      "274/274 [==============================] - 0s 389us/step - loss: 0.2206 - acc: 0.8978 - val_loss: 0.1402 - val_acc: 0.9032\n",
      "Epoch 145/500\n",
      "274/274 [==============================] - 0s 384us/step - loss: 0.2484 - acc: 0.9051 - val_loss: 0.1874 - val_acc: 0.8710\n",
      "Epoch 146/500\n",
      "274/274 [==============================] - 0s 391us/step - loss: 0.2458 - acc: 0.8686 - val_loss: 0.0922 - val_acc: 0.9677\n",
      "Epoch 147/500\n",
      "274/274 [==============================] - 0s 359us/step - loss: 0.2399 - acc: 0.9051 - val_loss: 0.1075 - val_acc: 0.9032\n",
      "Epoch 148/500\n",
      "274/274 [==============================] - 0s 363us/step - loss: 0.2197 - acc: 0.9088 - val_loss: 0.1161 - val_acc: 0.9032\n",
      "Epoch 149/500\n",
      "274/274 [==============================] - 0s 369us/step - loss: 0.2410 - acc: 0.8978 - val_loss: 0.0834 - val_acc: 0.9355\n",
      "Epoch 150/500\n",
      "274/274 [==============================] - 0s 352us/step - loss: 0.2306 - acc: 0.9015 - val_loss: 0.1006 - val_acc: 0.9032\n",
      "Epoch 151/500\n",
      "274/274 [==============================] - 0s 370us/step - loss: 0.2436 - acc: 0.8978 - val_loss: 0.0858 - val_acc: 0.9677\n",
      "Epoch 152/500\n",
      "274/274 [==============================] - 0s 377us/step - loss: 0.2286 - acc: 0.9015 - val_loss: 0.1029 - val_acc: 0.9032\n",
      "Epoch 153/500\n",
      "274/274 [==============================] - 0s 383us/step - loss: 0.2556 - acc: 0.8832 - val_loss: 0.1173 - val_acc: 0.9032\n",
      "Epoch 154/500\n",
      "274/274 [==============================] - 0s 379us/step - loss: 0.2700 - acc: 0.8905 - val_loss: 0.1270 - val_acc: 0.9032\n",
      "Epoch 155/500\n",
      "274/274 [==============================] - 0s 398us/step - loss: 0.2402 - acc: 0.8978 - val_loss: 0.2128 - val_acc: 0.8710\n",
      "Epoch 156/500\n",
      "274/274 [==============================] - 0s 358us/step - loss: 0.2442 - acc: 0.8832 - val_loss: 0.0959 - val_acc: 0.9032\n",
      "Epoch 157/500\n",
      "274/274 [==============================] - 0s 403us/step - loss: 0.2353 - acc: 0.8978 - val_loss: 0.0724 - val_acc: 1.0000\n",
      "Epoch 158/500\n",
      "274/274 [==============================] - 0s 393us/step - loss: 0.2276 - acc: 0.8978 - val_loss: 0.1191 - val_acc: 0.9032\n",
      "Epoch 159/500\n",
      "274/274 [==============================] - 0s 377us/step - loss: 0.2081 - acc: 0.9234 - val_loss: 0.0968 - val_acc: 0.9355\n",
      "Epoch 160/500\n",
      "274/274 [==============================] - 0s 407us/step - loss: 0.2216 - acc: 0.9307 - val_loss: 0.1375 - val_acc: 0.9032\n",
      "Epoch 161/500\n",
      "274/274 [==============================] - 0s 348us/step - loss: 0.2128 - acc: 0.9088 - val_loss: 0.1527 - val_acc: 0.9032\n",
      "Epoch 162/500\n",
      "274/274 [==============================] - 0s 391us/step - loss: 0.2080 - acc: 0.9124 - val_loss: 0.1471 - val_acc: 0.9032\n",
      "Epoch 163/500\n",
      "274/274 [==============================] - 0s 371us/step - loss: 0.2100 - acc: 0.9307 - val_loss: 0.1001 - val_acc: 0.9032\n",
      "Epoch 164/500\n",
      "274/274 [==============================] - 0s 389us/step - loss: 0.2536 - acc: 0.8942 - val_loss: 0.1181 - val_acc: 0.9032\n",
      "Epoch 165/500\n",
      "274/274 [==============================] - 0s 366us/step - loss: 0.2737 - acc: 0.8759 - val_loss: 0.0820 - val_acc: 0.9677\n",
      "Epoch 166/500\n",
      "274/274 [==============================] - 0s 386us/step - loss: 0.2707 - acc: 0.9015 - val_loss: 0.1304 - val_acc: 0.9032\n",
      "Epoch 167/500\n",
      "274/274 [==============================] - 0s 373us/step - loss: 0.2205 - acc: 0.9051 - val_loss: 0.0840 - val_acc: 0.9677\n",
      "Epoch 168/500\n",
      "274/274 [==============================] - 0s 374us/step - loss: 0.2153 - acc: 0.9124 - val_loss: 0.1606 - val_acc: 0.8710\n",
      "Epoch 169/500\n",
      "274/274 [==============================] - 0s 428us/step - loss: 0.2147 - acc: 0.9124 - val_loss: 0.0788 - val_acc: 0.9677\n",
      "Epoch 170/500\n",
      "274/274 [==============================] - 0s 383us/step - loss: 0.2255 - acc: 0.9088 - val_loss: 0.1530 - val_acc: 0.8710\n",
      "Epoch 171/500\n",
      "274/274 [==============================] - 0s 372us/step - loss: 0.2401 - acc: 0.8978 - val_loss: 0.1087 - val_acc: 0.9032\n",
      "Epoch 172/500\n",
      "274/274 [==============================] - 0s 361us/step - loss: 0.2094 - acc: 0.9234 - val_loss: 0.1572 - val_acc: 0.8710\n",
      "Epoch 173/500\n",
      "274/274 [==============================] - 0s 427us/step - loss: 0.1948 - acc: 0.9234 - val_loss: 0.0967 - val_acc: 0.9032\n",
      "Epoch 174/500\n",
      "274/274 [==============================] - 0s 384us/step - loss: 0.2070 - acc: 0.9197 - val_loss: 0.1514 - val_acc: 0.9032\n",
      "Epoch 175/500\n",
      "274/274 [==============================] - 0s 367us/step - loss: 0.1959 - acc: 0.9234 - val_loss: 0.1322 - val_acc: 0.9032\n",
      "Epoch 176/500\n",
      "274/274 [==============================] - 0s 381us/step - loss: 0.2207 - acc: 0.9161 - val_loss: 0.1700 - val_acc: 0.8710\n",
      "Epoch 177/500\n",
      "274/274 [==============================] - 0s 411us/step - loss: 0.2236 - acc: 0.9234 - val_loss: 0.1736 - val_acc: 0.8710\n",
      "Epoch 178/500\n",
      "274/274 [==============================] - 0s 425us/step - loss: 0.2167 - acc: 0.9088 - val_loss: 0.1096 - val_acc: 0.9032\n",
      "Epoch 179/500\n",
      "274/274 [==============================] - 0s 388us/step - loss: 0.1985 - acc: 0.9124 - val_loss: 0.1605 - val_acc: 0.9032\n",
      "Epoch 180/500\n",
      "274/274 [==============================] - 0s 410us/step - loss: 0.2223 - acc: 0.9088 - val_loss: 0.1686 - val_acc: 0.8710\n",
      "Epoch 181/500\n",
      "274/274 [==============================] - 0s 375us/step - loss: 0.2631 - acc: 0.9051 - val_loss: 0.1150 - val_acc: 0.9032\n",
      "Epoch 182/500\n",
      "274/274 [==============================] - 0s 436us/step - loss: 0.2171 - acc: 0.9161 - val_loss: 0.1370 - val_acc: 0.9032\n",
      "Epoch 183/500\n",
      "274/274 [==============================] - 0s 423us/step - loss: 0.2137 - acc: 0.9307 - val_loss: 0.3228 - val_acc: 0.8710\n",
      "Epoch 184/500\n",
      "274/274 [==============================] - 0s 447us/step - loss: 0.2406 - acc: 0.8869 - val_loss: 0.1690 - val_acc: 0.8710\n",
      "Epoch 185/500\n",
      "274/274 [==============================] - 0s 476us/step - loss: 0.2123 - acc: 0.9015 - val_loss: 0.1233 - val_acc: 0.9032\n",
      "Epoch 186/500\n",
      "274/274 [==============================] - 0s 438us/step - loss: 0.2110 - acc: 0.9051 - val_loss: 0.1999 - val_acc: 0.8710\n",
      "Epoch 187/500\n",
      "274/274 [==============================] - 0s 447us/step - loss: 0.2554 - acc: 0.8759 - val_loss: 0.2314 - val_acc: 0.8710\n",
      "Epoch 188/500\n",
      "274/274 [==============================] - 0s 430us/step - loss: 0.2039 - acc: 0.9088 - val_loss: 0.1438 - val_acc: 0.9032\n",
      "Epoch 189/500\n",
      "274/274 [==============================] - 0s 411us/step - loss: 0.1995 - acc: 0.9234 - val_loss: 0.1435 - val_acc: 0.9032\n",
      "Epoch 190/500\n",
      "274/274 [==============================] - 0s 363us/step - loss: 0.1904 - acc: 0.9197 - val_loss: 0.1785 - val_acc: 0.9032\n",
      "Epoch 191/500\n",
      "274/274 [==============================] - 0s 382us/step - loss: 0.1991 - acc: 0.9270 - val_loss: 0.1694 - val_acc: 0.9032\n",
      "Epoch 192/500\n",
      "274/274 [==============================] - 0s 392us/step - loss: 0.1965 - acc: 0.9234 - val_loss: 0.1646 - val_acc: 0.9032\n",
      "Epoch 193/500\n",
      "274/274 [==============================] - 0s 454us/step - loss: 0.1924 - acc: 0.9124 - val_loss: 0.2352 - val_acc: 0.8710\n",
      "Epoch 194/500\n",
      "274/274 [==============================] - 0s 430us/step - loss: 0.2102 - acc: 0.9270 - val_loss: 0.3184 - val_acc: 0.8710\n",
      "Epoch 195/500\n",
      "274/274 [==============================] - 0s 404us/step - loss: 0.2623 - acc: 0.8942 - val_loss: 0.2031 - val_acc: 0.8710\n",
      "Epoch 196/500\n",
      "274/274 [==============================] - 0s 422us/step - loss: 0.2388 - acc: 0.8905 - val_loss: 0.1277 - val_acc: 0.9032\n",
      "Epoch 197/500\n",
      "274/274 [==============================] - 0s 433us/step - loss: 0.2055 - acc: 0.9015 - val_loss: 0.0779 - val_acc: 0.9677\n",
      "Epoch 198/500\n",
      "274/274 [==============================] - 0s 459us/step - loss: 0.2197 - acc: 0.9051 - val_loss: 0.1274 - val_acc: 0.9032\n",
      "Epoch 199/500\n",
      "274/274 [==============================] - 0s 508us/step - loss: 0.1943 - acc: 0.9088 - val_loss: 0.2383 - val_acc: 0.8710\n",
      "Epoch 200/500\n",
      "274/274 [==============================] - 0s 423us/step - loss: 0.2207 - acc: 0.9051 - val_loss: 0.1810 - val_acc: 0.8710\n",
      "Epoch 201/500\n",
      "274/274 [==============================] - 0s 469us/step - loss: 0.1930 - acc: 0.9343 - val_loss: 0.1563 - val_acc: 0.9032\n",
      "Epoch 202/500\n",
      "274/274 [==============================] - 0s 465us/step - loss: 0.1904 - acc: 0.9161 - val_loss: 0.1883 - val_acc: 0.8710\n",
      "Epoch 203/500\n",
      "274/274 [==============================] - 0s 393us/step - loss: 0.1875 - acc: 0.9234 - val_loss: 0.1951 - val_acc: 0.8710\n",
      "Epoch 204/500\n",
      "274/274 [==============================] - 0s 377us/step - loss: 0.1884 - acc: 0.9088 - val_loss: 0.1858 - val_acc: 0.9032\n",
      "Epoch 205/500\n",
      "274/274 [==============================] - 0s 350us/step - loss: 0.1899 - acc: 0.9234 - val_loss: 0.1595 - val_acc: 0.9032\n",
      "Epoch 206/500\n",
      "274/274 [==============================] - 0s 386us/step - loss: 0.2193 - acc: 0.9051 - val_loss: 0.0827 - val_acc: 0.9677\n",
      "Epoch 207/500\n",
      "274/274 [==============================] - 0s 365us/step - loss: 0.2195 - acc: 0.9088 - val_loss: 0.1306 - val_acc: 0.9032\n",
      "Epoch 208/500\n",
      "274/274 [==============================] - 0s 407us/step - loss: 0.1938 - acc: 0.9270 - val_loss: 0.1289 - val_acc: 0.9032\n",
      "Epoch 209/500\n",
      "274/274 [==============================] - 0s 431us/step - loss: 0.2039 - acc: 0.9124 - val_loss: 0.0640 - val_acc: 1.0000\n",
      "Epoch 210/500\n",
      "274/274 [==============================] - 0s 367us/step - loss: 0.2553 - acc: 0.8978 - val_loss: 0.1065 - val_acc: 0.9032\n",
      "Epoch 211/500\n",
      "274/274 [==============================] - 0s 475us/step - loss: 0.2025 - acc: 0.9234 - val_loss: 0.2427 - val_acc: 0.8710\n",
      "Epoch 212/500\n",
      "274/274 [==============================] - 0s 339us/step - loss: 0.2079 - acc: 0.9051 - val_loss: 0.1730 - val_acc: 0.9032\n",
      "Epoch 213/500\n",
      "274/274 [==============================] - 0s 382us/step - loss: 0.2056 - acc: 0.9124 - val_loss: 0.1573 - val_acc: 0.9032\n",
      "Epoch 214/500\n",
      "274/274 [==============================] - 0s 353us/step - loss: 0.2018 - acc: 0.9088 - val_loss: 0.1226 - val_acc: 0.9355\n",
      "Epoch 215/500\n",
      "274/274 [==============================] - 0s 385us/step - loss: 0.2038 - acc: 0.9161 - val_loss: 0.2546 - val_acc: 0.8710\n",
      "Epoch 216/500\n",
      "274/274 [==============================] - 0s 376us/step - loss: 0.1941 - acc: 0.9197 - val_loss: 0.1965 - val_acc: 0.9032\n",
      "Epoch 217/500\n",
      "274/274 [==============================] - 0s 384us/step - loss: 0.1880 - acc: 0.9234 - val_loss: 0.2396 - val_acc: 0.8710\n",
      "Epoch 218/500\n",
      "274/274 [==============================] - 0s 395us/step - loss: 0.1909 - acc: 0.9197 - val_loss: 0.2606 - val_acc: 0.8710\n",
      "Epoch 219/500\n",
      "274/274 [==============================] - 0s 376us/step - loss: 0.1891 - acc: 0.9234 - val_loss: 0.1768 - val_acc: 0.9032\n",
      "Epoch 220/500\n",
      "274/274 [==============================] - 0s 381us/step - loss: 0.2287 - acc: 0.9161 - val_loss: 0.1642 - val_acc: 0.8710\n",
      "Epoch 221/500\n",
      "274/274 [==============================] - 0s 382us/step - loss: 0.1934 - acc: 0.9234 - val_loss: 0.2412 - val_acc: 0.8710\n",
      "Epoch 222/500\n",
      "274/274 [==============================] - 0s 372us/step - loss: 0.1920 - acc: 0.9161 - val_loss: 0.2347 - val_acc: 0.8710\n",
      "Epoch 223/500\n",
      "274/274 [==============================] - 0s 390us/step - loss: 0.1880 - acc: 0.9234 - val_loss: 0.1518 - val_acc: 0.9032\n",
      "Epoch 224/500\n",
      "274/274 [==============================] - 0s 408us/step - loss: 0.1887 - acc: 0.9270 - val_loss: 0.2129 - val_acc: 0.9032\n",
      "Epoch 225/500\n",
      "274/274 [==============================] - 0s 378us/step - loss: 0.1846 - acc: 0.9161 - val_loss: 0.2352 - val_acc: 0.8710\n",
      "Epoch 226/500\n",
      "274/274 [==============================] - 0s 387us/step - loss: 0.2053 - acc: 0.9124 - val_loss: 0.1700 - val_acc: 0.8710\n",
      "Epoch 227/500\n",
      "274/274 [==============================] - 0s 406us/step - loss: 0.2352 - acc: 0.8832 - val_loss: 0.1175 - val_acc: 0.8710\n",
      "Epoch 228/500\n",
      "274/274 [==============================] - 0s 443us/step - loss: 0.1937 - acc: 0.9270 - val_loss: 0.2510 - val_acc: 0.9032\n",
      "Epoch 229/500\n",
      "274/274 [==============================] - 0s 412us/step - loss: 0.1799 - acc: 0.9270 - val_loss: 0.1889 - val_acc: 0.9032\n",
      "Epoch 230/500\n",
      "274/274 [==============================] - 0s 428us/step - loss: 0.1861 - acc: 0.9234 - val_loss: 0.0833 - val_acc: 0.9355\n",
      "Epoch 231/500\n",
      "274/274 [==============================] - 0s 408us/step - loss: 0.2549 - acc: 0.8759 - val_loss: 0.0969 - val_acc: 0.9032\n",
      "Epoch 232/500\n",
      "274/274 [==============================] - 0s 446us/step - loss: 0.2198 - acc: 0.9161 - val_loss: 0.1351 - val_acc: 0.9032\n",
      "Epoch 233/500\n",
      "274/274 [==============================] - 0s 403us/step - loss: 0.2250 - acc: 0.9015 - val_loss: 0.1765 - val_acc: 0.8710\n",
      "Epoch 234/500\n",
      "274/274 [==============================] - 0s 421us/step - loss: 0.1984 - acc: 0.9051 - val_loss: 0.2630 - val_acc: 0.8710\n",
      "Epoch 235/500\n",
      "274/274 [==============================] - 0s 413us/step - loss: 0.1802 - acc: 0.9307 - val_loss: 0.1551 - val_acc: 0.9032\n",
      "Epoch 236/500\n",
      "274/274 [==============================] - 0s 429us/step - loss: 0.1896 - acc: 0.9161 - val_loss: 0.1852 - val_acc: 0.8710\n",
      "Epoch 237/500\n",
      "274/274 [==============================] - 0s 420us/step - loss: 0.1751 - acc: 0.9343 - val_loss: 0.2655 - val_acc: 0.8710\n",
      "Epoch 238/500\n",
      "274/274 [==============================] - 0s 436us/step - loss: 0.2113 - acc: 0.9161 - val_loss: 0.1478 - val_acc: 0.8710\n",
      "Epoch 239/500\n",
      "274/274 [==============================] - 0s 419us/step - loss: 0.1780 - acc: 0.9197 - val_loss: 0.2248 - val_acc: 0.8710\n",
      "Epoch 240/500\n",
      "274/274 [==============================] - 0s 452us/step - loss: 0.1963 - acc: 0.9088 - val_loss: 0.3281 - val_acc: 0.8710\n",
      "Epoch 241/500\n",
      "274/274 [==============================] - 0s 468us/step - loss: 0.2068 - acc: 0.9161 - val_loss: 0.3000 - val_acc: 0.8710\n",
      "Epoch 242/500\n",
      "274/274 [==============================] - 0s 450us/step - loss: 0.1792 - acc: 0.9234 - val_loss: 0.2481 - val_acc: 0.9032\n",
      "Epoch 243/500\n",
      "274/274 [==============================] - 0s 460us/step - loss: 0.1629 - acc: 0.9343 - val_loss: 0.1773 - val_acc: 0.9032\n",
      "Epoch 244/500\n",
      "274/274 [==============================] - 0s 460us/step - loss: 0.1672 - acc: 0.9270 - val_loss: 0.2159 - val_acc: 0.9032\n",
      "Epoch 245/500\n",
      "274/274 [==============================] - 0s 373us/step - loss: 0.1956 - acc: 0.9234 - val_loss: 0.0628 - val_acc: 0.9677\n",
      "Epoch 246/500\n",
      "274/274 [==============================] - 0s 409us/step - loss: 0.2797 - acc: 0.8905 - val_loss: 0.1014 - val_acc: 0.9032\n",
      "Epoch 247/500\n",
      "274/274 [==============================] - 0s 409us/step - loss: 0.2095 - acc: 0.8978 - val_loss: 0.1495 - val_acc: 0.9032\n",
      "Epoch 248/500\n",
      "274/274 [==============================] - 0s 475us/step - loss: 0.1875 - acc: 0.9270 - val_loss: 0.1807 - val_acc: 0.9032\n",
      "Epoch 249/500\n",
      "274/274 [==============================] - 0s 421us/step - loss: 0.1802 - acc: 0.9307 - val_loss: 0.2144 - val_acc: 0.9032\n",
      "Epoch 250/500\n",
      "274/274 [==============================] - 0s 397us/step - loss: 0.1709 - acc: 0.9307 - val_loss: 0.2949 - val_acc: 0.8710\n",
      "Epoch 251/500\n",
      "274/274 [==============================] - 0s 399us/step - loss: 0.1668 - acc: 0.9307 - val_loss: 0.3832 - val_acc: 0.8710\n",
      "Epoch 252/500\n",
      "274/274 [==============================] - 0s 421us/step - loss: 0.1929 - acc: 0.9307 - val_loss: 0.2619 - val_acc: 0.8710\n",
      "Epoch 253/500\n",
      "274/274 [==============================] - 0s 423us/step - loss: 0.1972 - acc: 0.9124 - val_loss: 0.2719 - val_acc: 0.8710\n",
      "Epoch 254/500\n",
      "274/274 [==============================] - 0s 453us/step - loss: 0.1662 - acc: 0.9343 - val_loss: 0.2628 - val_acc: 0.9032\n",
      "Epoch 255/500\n",
      "274/274 [==============================] - 0s 412us/step - loss: 0.1689 - acc: 0.9270 - val_loss: 0.2191 - val_acc: 0.9032\n",
      "Epoch 256/500\n",
      "274/274 [==============================] - 0s 421us/step - loss: 0.1896 - acc: 0.9088 - val_loss: 0.2913 - val_acc: 0.8710\n",
      "Epoch 257/500\n",
      "274/274 [==============================] - 0s 424us/step - loss: 0.1681 - acc: 0.9343 - val_loss: 0.3627 - val_acc: 0.8710\n",
      "Epoch 258/500\n",
      "274/274 [==============================] - 0s 422us/step - loss: 0.1730 - acc: 0.9234 - val_loss: 0.3312 - val_acc: 0.8710\n",
      "Epoch 259/500\n",
      "274/274 [==============================] - 0s 417us/step - loss: 0.1584 - acc: 0.9380 - val_loss: 0.2473 - val_acc: 0.9032\n",
      "Epoch 260/500\n",
      "274/274 [==============================] - 0s 378us/step - loss: 0.1615 - acc: 0.9380 - val_loss: 0.3094 - val_acc: 0.8710\n",
      "Epoch 261/500\n",
      "274/274 [==============================] - 0s 419us/step - loss: 0.1655 - acc: 0.9307 - val_loss: 0.4450 - val_acc: 0.8710\n",
      "Epoch 262/500\n",
      "274/274 [==============================] - 0s 418us/step - loss: 0.1637 - acc: 0.9234 - val_loss: 0.2498 - val_acc: 0.9032\n",
      "Epoch 263/500\n",
      "274/274 [==============================] - 0s 444us/step - loss: 0.3727 - acc: 0.8431 - val_loss: 0.1707 - val_acc: 0.8710\n",
      "Epoch 264/500\n",
      "274/274 [==============================] - 0s 451us/step - loss: 0.2301 - acc: 0.9124 - val_loss: 0.1356 - val_acc: 0.9032\n",
      "Epoch 265/500\n",
      "274/274 [==============================] - 0s 424us/step - loss: 0.2216 - acc: 0.9015 - val_loss: 0.1115 - val_acc: 0.9032\n",
      "Epoch 266/500\n",
      "274/274 [==============================] - 0s 388us/step - loss: 0.2089 - acc: 0.9015 - val_loss: 0.2410 - val_acc: 0.8710\n",
      "Epoch 267/500\n",
      "274/274 [==============================] - 0s 435us/step - loss: 0.2652 - acc: 0.8978 - val_loss: 0.1813 - val_acc: 0.9032\n",
      "Epoch 268/500\n",
      "274/274 [==============================] - 0s 425us/step - loss: 0.2214 - acc: 0.9088 - val_loss: 0.0974 - val_acc: 0.9677\n",
      "Epoch 269/500\n",
      "274/274 [==============================] - 0s 379us/step - loss: 0.2083 - acc: 0.9051 - val_loss: 0.0861 - val_acc: 0.9355\n",
      "Epoch 270/500\n",
      "274/274 [==============================] - 0s 362us/step - loss: 0.1973 - acc: 0.9124 - val_loss: 0.1651 - val_acc: 0.9032\n",
      "Epoch 271/500\n",
      "274/274 [==============================] - 0s 382us/step - loss: 0.2003 - acc: 0.9088 - val_loss: 0.1696 - val_acc: 0.9032\n",
      "Epoch 272/500\n",
      "274/274 [==============================] - 0s 407us/step - loss: 0.1938 - acc: 0.9234 - val_loss: 0.1741 - val_acc: 0.9032\n",
      "Epoch 273/500\n",
      "274/274 [==============================] - 0s 373us/step - loss: 0.2024 - acc: 0.9161 - val_loss: 0.1390 - val_acc: 0.9032\n",
      "Epoch 274/500\n",
      "274/274 [==============================] - 0s 410us/step - loss: 0.1889 - acc: 0.9197 - val_loss: 0.2111 - val_acc: 0.9032\n",
      "Epoch 275/500\n",
      "274/274 [==============================] - 0s 368us/step - loss: 0.1785 - acc: 0.9234 - val_loss: 0.2889 - val_acc: 0.9032\n",
      "Epoch 276/500\n",
      "274/274 [==============================] - 0s 389us/step - loss: 0.1771 - acc: 0.9197 - val_loss: 0.3612 - val_acc: 0.8710\n",
      "Epoch 277/500\n",
      "274/274 [==============================] - 0s 355us/step - loss: 0.1665 - acc: 0.9270 - val_loss: 0.3601 - val_acc: 0.9032\n",
      "Epoch 278/500\n",
      "274/274 [==============================] - 0s 383us/step - loss: 0.1693 - acc: 0.9380 - val_loss: 0.3200 - val_acc: 0.9032\n",
      "Epoch 279/500\n",
      "274/274 [==============================] - 0s 385us/step - loss: 0.1643 - acc: 0.9307 - val_loss: 0.3588 - val_acc: 0.9032\n",
      "Epoch 280/500\n",
      "274/274 [==============================] - 0s 400us/step - loss: 0.1626 - acc: 0.9307 - val_loss: 0.3967 - val_acc: 0.9032\n",
      "Epoch 281/500\n",
      "274/274 [==============================] - 0s 353us/step - loss: 0.2202 - acc: 0.9088 - val_loss: 0.1294 - val_acc: 0.9355\n",
      "Epoch 282/500\n",
      "274/274 [==============================] - 0s 380us/step - loss: 0.1907 - acc: 0.9197 - val_loss: 0.2262 - val_acc: 0.8710\n",
      "Epoch 283/500\n",
      "274/274 [==============================] - 0s 393us/step - loss: 0.2543 - acc: 0.8978 - val_loss: 0.1066 - val_acc: 0.9032\n",
      "Epoch 284/500\n",
      "274/274 [==============================] - 0s 413us/step - loss: 0.2208 - acc: 0.9015 - val_loss: 0.0984 - val_acc: 0.9677\n",
      "Epoch 285/500\n",
      "274/274 [==============================] - 0s 358us/step - loss: 0.1945 - acc: 0.9234 - val_loss: 0.2263 - val_acc: 0.9032\n",
      "Epoch 286/500\n",
      "274/274 [==============================] - 0s 344us/step - loss: 0.1724 - acc: 0.9270 - val_loss: 0.2231 - val_acc: 0.9032\n",
      "Epoch 287/500\n",
      "274/274 [==============================] - 0s 375us/step - loss: 0.1807 - acc: 0.9197 - val_loss: 0.2771 - val_acc: 0.9032\n",
      "Epoch 288/500\n",
      "274/274 [==============================] - 0s 384us/step - loss: 0.1925 - acc: 0.9270 - val_loss: 0.3890 - val_acc: 0.8710\n",
      "Epoch 289/500\n",
      "274/274 [==============================] - 0s 392us/step - loss: 0.2018 - acc: 0.9088 - val_loss: 0.3076 - val_acc: 0.8710\n",
      "Epoch 290/500\n",
      "274/274 [==============================] - 0s 374us/step - loss: 0.1982 - acc: 0.9270 - val_loss: 0.3977 - val_acc: 0.8710\n",
      "Epoch 291/500\n",
      "274/274 [==============================] - 0s 368us/step - loss: 0.1628 - acc: 0.9343 - val_loss: 0.3068 - val_acc: 0.9032\n",
      "Epoch 292/500\n",
      "274/274 [==============================] - 0s 405us/step - loss: 0.1631 - acc: 0.9270 - val_loss: 0.0932 - val_acc: 0.9355\n",
      "Epoch 293/500\n",
      "274/274 [==============================] - 0s 364us/step - loss: 0.1781 - acc: 0.9161 - val_loss: 0.1931 - val_acc: 0.9032\n",
      "Epoch 294/500\n",
      "274/274 [==============================] - 0s 379us/step - loss: 0.1642 - acc: 0.9343 - val_loss: 0.3492 - val_acc: 0.9032\n",
      "Epoch 295/500\n",
      "274/274 [==============================] - 0s 365us/step - loss: 0.1599 - acc: 0.9343 - val_loss: 0.4059 - val_acc: 0.8710\n",
      "Epoch 296/500\n",
      "274/274 [==============================] - 0s 427us/step - loss: 0.1628 - acc: 0.9234 - val_loss: 0.4606 - val_acc: 0.8710\n",
      "Epoch 297/500\n",
      "274/274 [==============================] - 0s 465us/step - loss: 0.1789 - acc: 0.9234 - val_loss: 0.3928 - val_acc: 0.8710\n",
      "Epoch 298/500\n",
      "274/274 [==============================] - 0s 379us/step - loss: 0.1602 - acc: 0.9307 - val_loss: 0.2455 - val_acc: 0.8710\n",
      "Epoch 299/500\n",
      "274/274 [==============================] - 0s 374us/step - loss: 0.1525 - acc: 0.9416 - val_loss: 0.3302 - val_acc: 0.8710\n",
      "Epoch 300/500\n",
      "274/274 [==============================] - 0s 355us/step - loss: 0.1516 - acc: 0.9453 - val_loss: 0.4337 - val_acc: 0.8710\n",
      "Epoch 301/500\n",
      "274/274 [==============================] - 0s 383us/step - loss: 0.1497 - acc: 0.9343 - val_loss: 0.5755 - val_acc: 0.8710\n",
      "Epoch 302/500\n",
      "274/274 [==============================] - 0s 441us/step - loss: 0.1627 - acc: 0.9234 - val_loss: 0.2285 - val_acc: 0.9032\n",
      "Epoch 303/500\n",
      "274/274 [==============================] - 0s 430us/step - loss: 0.1597 - acc: 0.9307 - val_loss: 0.3501 - val_acc: 0.8710\n",
      "Epoch 304/500\n",
      "274/274 [==============================] - 0s 401us/step - loss: 0.1901 - acc: 0.9161 - val_loss: 0.3690 - val_acc: 0.8710\n",
      "Epoch 305/500\n",
      "274/274 [==============================] - 0s 383us/step - loss: 0.1659 - acc: 0.9343 - val_loss: 0.3350 - val_acc: 0.9032\n",
      "Epoch 306/500\n",
      "274/274 [==============================] - 0s 388us/step - loss: 0.1518 - acc: 0.9380 - val_loss: 0.5287 - val_acc: 0.8710\n",
      "Epoch 307/500\n",
      "274/274 [==============================] - 0s 361us/step - loss: 0.1643 - acc: 0.9270 - val_loss: 0.3495 - val_acc: 0.8710\n",
      "Epoch 308/500\n",
      "274/274 [==============================] - 0s 379us/step - loss: 0.1721 - acc: 0.9234 - val_loss: 0.2987 - val_acc: 0.8710\n",
      "Epoch 309/500\n",
      "274/274 [==============================] - 0s 385us/step - loss: 0.1720 - acc: 0.9380 - val_loss: 0.1869 - val_acc: 0.9032\n",
      "Epoch 310/500\n",
      "274/274 [==============================] - 0s 363us/step - loss: 0.1649 - acc: 0.9307 - val_loss: 0.1598 - val_acc: 0.9032\n",
      "Epoch 311/500\n",
      "274/274 [==============================] - 0s 358us/step - loss: 0.1813 - acc: 0.9197 - val_loss: 0.1945 - val_acc: 0.9032\n",
      "Epoch 312/500\n",
      "274/274 [==============================] - 0s 363us/step - loss: 0.2046 - acc: 0.8978 - val_loss: 0.2246 - val_acc: 0.8710\n",
      "Epoch 313/500\n",
      "274/274 [==============================] - 0s 364us/step - loss: 0.1797 - acc: 0.9307 - val_loss: 0.1965 - val_acc: 0.8710\n",
      "Epoch 314/500\n",
      "274/274 [==============================] - 0s 394us/step - loss: 0.1573 - acc: 0.9270 - val_loss: 0.1819 - val_acc: 0.9032\n",
      "Epoch 315/500\n",
      "274/274 [==============================] - 0s 405us/step - loss: 0.1484 - acc: 0.9380 - val_loss: 0.0730 - val_acc: 0.9355\n",
      "Epoch 316/500\n",
      "274/274 [==============================] - 0s 394us/step - loss: 0.1849 - acc: 0.9270 - val_loss: 0.1159 - val_acc: 0.9032\n",
      "Epoch 317/500\n",
      "274/274 [==============================] - 0s 375us/step - loss: 0.1755 - acc: 0.9453 - val_loss: 0.1544 - val_acc: 0.9032\n",
      "Epoch 318/500\n",
      "274/274 [==============================] - 0s 360us/step - loss: 0.2053 - acc: 0.8978 - val_loss: 0.2101 - val_acc: 0.8710\n",
      "Epoch 319/500\n",
      "274/274 [==============================] - 0s 385us/step - loss: 0.1707 - acc: 0.9343 - val_loss: 0.3080 - val_acc: 0.9032\n",
      "Epoch 320/500\n",
      "274/274 [==============================] - 0s 370us/step - loss: 0.1438 - acc: 0.9453 - val_loss: 0.3371 - val_acc: 0.9032\n",
      "Epoch 321/500\n",
      "274/274 [==============================] - 0s 372us/step - loss: 0.1451 - acc: 0.9489 - val_loss: 0.4208 - val_acc: 0.8710\n",
      "Epoch 322/500\n",
      "274/274 [==============================] - 0s 366us/step - loss: 0.2075 - acc: 0.9051 - val_loss: 0.0903 - val_acc: 0.9355\n",
      "Epoch 323/500\n",
      "274/274 [==============================] - 0s 367us/step - loss: 0.1881 - acc: 0.9124 - val_loss: 0.0388 - val_acc: 0.9677\n",
      "Epoch 324/500\n",
      "274/274 [==============================] - 0s 385us/step - loss: 0.2105 - acc: 0.9124 - val_loss: 0.2177 - val_acc: 0.8710\n",
      "Epoch 325/500\n",
      "274/274 [==============================] - 0s 409us/step - loss: 0.1611 - acc: 0.9234 - val_loss: 0.2204 - val_acc: 0.8710\n",
      "Epoch 326/500\n",
      "274/274 [==============================] - 0s 403us/step - loss: 0.1464 - acc: 0.9416 - val_loss: 0.4638 - val_acc: 0.8710\n",
      "Epoch 327/500\n",
      "274/274 [==============================] - 0s 450us/step - loss: 0.1684 - acc: 0.9380 - val_loss: 0.3402 - val_acc: 0.8710\n",
      "Epoch 328/500\n",
      "274/274 [==============================] - 0s 453us/step - loss: 0.1543 - acc: 0.9307 - val_loss: 0.4024 - val_acc: 0.8710\n",
      "Epoch 329/500\n",
      "274/274 [==============================] - 0s 409us/step - loss: 0.1555 - acc: 0.9526 - val_loss: 0.3712 - val_acc: 0.9032\n",
      "Epoch 330/500\n",
      "274/274 [==============================] - 0s 420us/step - loss: 0.1529 - acc: 0.9453 - val_loss: 0.2039 - val_acc: 0.9032\n",
      "Epoch 331/500\n",
      "274/274 [==============================] - 0s 408us/step - loss: 0.1453 - acc: 0.9416 - val_loss: 0.2401 - val_acc: 0.9032\n",
      "Epoch 332/500\n",
      "274/274 [==============================] - 0s 371us/step - loss: 0.1485 - acc: 0.9307 - val_loss: 0.4123 - val_acc: 0.9032\n",
      "Epoch 333/500\n",
      "274/274 [==============================] - 0s 435us/step - loss: 0.1368 - acc: 0.9526 - val_loss: 0.4128 - val_acc: 0.8710\n",
      "Epoch 334/500\n",
      "274/274 [==============================] - 0s 445us/step - loss: 0.1339 - acc: 0.9453 - val_loss: 0.4452 - val_acc: 0.8710\n",
      "Epoch 335/500\n",
      "274/274 [==============================] - 0s 499us/step - loss: 0.1331 - acc: 0.9526 - val_loss: 0.5612 - val_acc: 0.8710\n",
      "Epoch 336/500\n",
      "274/274 [==============================] - 0s 484us/step - loss: 0.1622 - acc: 0.9380 - val_loss: 0.6086 - val_acc: 0.8710\n",
      "Epoch 337/500\n",
      "274/274 [==============================] - 0s 421us/step - loss: 0.1500 - acc: 0.9453 - val_loss: 0.4156 - val_acc: 0.8710\n",
      "Epoch 338/500\n",
      "274/274 [==============================] - 0s 411us/step - loss: 0.1525 - acc: 0.9526 - val_loss: 0.3995 - val_acc: 0.8710\n",
      "Epoch 339/500\n",
      "274/274 [==============================] - 0s 412us/step - loss: 0.1836 - acc: 0.9197 - val_loss: 0.2506 - val_acc: 0.8710\n",
      "Epoch 340/500\n",
      "274/274 [==============================] - 0s 433us/step - loss: 0.1750 - acc: 0.9343 - val_loss: 0.2303 - val_acc: 0.8710\n",
      "Epoch 341/500\n",
      "274/274 [==============================] - 0s 372us/step - loss: 0.1516 - acc: 0.9453 - val_loss: 0.4457 - val_acc: 0.8710\n",
      "Epoch 342/500\n",
      "274/274 [==============================] - 0s 353us/step - loss: 0.1493 - acc: 0.9343 - val_loss: 0.7340 - val_acc: 0.8710\n",
      "Epoch 343/500\n",
      "274/274 [==============================] - 0s 438us/step - loss: 0.1726 - acc: 0.9343 - val_loss: 0.2903 - val_acc: 0.9032\n",
      "Epoch 344/500\n",
      "274/274 [==============================] - 0s 414us/step - loss: 0.1571 - acc: 0.9307 - val_loss: 0.3626 - val_acc: 0.9032\n",
      "Epoch 345/500\n",
      "274/274 [==============================] - 0s 448us/step - loss: 0.1780 - acc: 0.9234 - val_loss: 0.2384 - val_acc: 0.8710\n",
      "Epoch 346/500\n",
      "274/274 [==============================] - 0s 433us/step - loss: 0.1638 - acc: 0.9270 - val_loss: 0.2927 - val_acc: 0.8710\n",
      "Epoch 347/500\n",
      "274/274 [==============================] - 0s 427us/step - loss: 0.1562 - acc: 0.9416 - val_loss: 0.2243 - val_acc: 0.8710\n",
      "Epoch 348/500\n",
      "274/274 [==============================] - 0s 449us/step - loss: 0.1679 - acc: 0.9416 - val_loss: 0.2440 - val_acc: 0.8710\n",
      "Epoch 349/500\n",
      "274/274 [==============================] - 0s 476us/step - loss: 0.2531 - acc: 0.9015 - val_loss: 0.1563 - val_acc: 0.9032\n",
      "Epoch 350/500\n",
      "274/274 [==============================] - 0s 429us/step - loss: 0.1819 - acc: 0.9307 - val_loss: 0.1666 - val_acc: 0.9032\n",
      "Epoch 351/500\n",
      "274/274 [==============================] - 0s 371us/step - loss: 0.1642 - acc: 0.9197 - val_loss: 0.3407 - val_acc: 0.8710\n",
      "Epoch 352/500\n",
      "274/274 [==============================] - 0s 405us/step - loss: 0.1790 - acc: 0.9161 - val_loss: 0.3493 - val_acc: 0.8710\n",
      "Epoch 353/500\n",
      "274/274 [==============================] - 0s 384us/step - loss: 0.1843 - acc: 0.9234 - val_loss: 0.1265 - val_acc: 0.9032\n",
      "Epoch 354/500\n",
      "274/274 [==============================] - 0s 393us/step - loss: 0.1566 - acc: 0.9307 - val_loss: 0.1095 - val_acc: 0.9355\n",
      "Epoch 355/500\n",
      "274/274 [==============================] - 0s 398us/step - loss: 0.1630 - acc: 0.9307 - val_loss: 0.1060 - val_acc: 0.9355\n",
      "Epoch 356/500\n",
      "274/274 [==============================] - 0s 384us/step - loss: 0.1362 - acc: 0.9453 - val_loss: 0.5175 - val_acc: 0.8710\n",
      "Epoch 357/500\n",
      "274/274 [==============================] - 0s 386us/step - loss: 0.2187 - acc: 0.9015 - val_loss: 0.4050 - val_acc: 0.8710\n",
      "Epoch 358/500\n",
      "274/274 [==============================] - 0s 375us/step - loss: 0.1796 - acc: 0.9197 - val_loss: 0.2589 - val_acc: 0.8710\n",
      "Epoch 359/500\n",
      "274/274 [==============================] - 0s 411us/step - loss: 0.1409 - acc: 0.9453 - val_loss: 0.1570 - val_acc: 0.9032\n",
      "Epoch 360/500\n",
      "274/274 [==============================] - 0s 408us/step - loss: 0.1430 - acc: 0.9380 - val_loss: 0.2560 - val_acc: 0.8710\n",
      "Epoch 361/500\n",
      "274/274 [==============================] - 0s 377us/step - loss: 0.1579 - acc: 0.9380 - val_loss: 0.4337 - val_acc: 0.8710\n",
      "Epoch 362/500\n",
      "274/274 [==============================] - 0s 385us/step - loss: 0.1602 - acc: 0.9270 - val_loss: 0.3021 - val_acc: 0.8710\n",
      "Epoch 363/500\n",
      "274/274 [==============================] - 0s 425us/step - loss: 0.1470 - acc: 0.9526 - val_loss: 0.1051 - val_acc: 0.9677\n",
      "Epoch 364/500\n",
      "274/274 [==============================] - 0s 477us/step - loss: 0.2054 - acc: 0.8978 - val_loss: 0.0515 - val_acc: 0.9677\n",
      "Epoch 365/500\n",
      "274/274 [==============================] - 0s 460us/step - loss: 0.1557 - acc: 0.9380 - val_loss: 0.4100 - val_acc: 0.8710\n",
      "Epoch 366/500\n",
      "274/274 [==============================] - 0s 467us/step - loss: 0.1761 - acc: 0.9124 - val_loss: 0.2276 - val_acc: 0.9032\n",
      "Epoch 367/500\n",
      "274/274 [==============================] - 0s 414us/step - loss: 0.1474 - acc: 0.9526 - val_loss: 0.2992 - val_acc: 0.9032\n",
      "Epoch 368/500\n",
      "274/274 [==============================] - 0s 467us/step - loss: 0.1337 - acc: 0.9526 - val_loss: 0.3241 - val_acc: 0.9032\n",
      "Epoch 369/500\n",
      "274/274 [==============================] - 0s 450us/step - loss: 0.1389 - acc: 0.9526 - val_loss: 0.3843 - val_acc: 0.9032\n",
      "Epoch 370/500\n",
      "274/274 [==============================] - 0s 370us/step - loss: 0.1404 - acc: 0.9416 - val_loss: 0.0841 - val_acc: 0.9677\n",
      "Epoch 371/500\n",
      "274/274 [==============================] - 0s 361us/step - loss: 0.1472 - acc: 0.9343 - val_loss: 0.3812 - val_acc: 0.9032\n",
      "Epoch 372/500\n",
      "274/274 [==============================] - 0s 377us/step - loss: 0.1530 - acc: 0.9270 - val_loss: 0.3472 - val_acc: 0.9032\n",
      "Epoch 373/500\n",
      "274/274 [==============================] - 0s 353us/step - loss: 0.1399 - acc: 0.9416 - val_loss: 0.3630 - val_acc: 0.9032\n",
      "Epoch 374/500\n",
      "274/274 [==============================] - 0s 414us/step - loss: 0.1672 - acc: 0.9161 - val_loss: 0.3989 - val_acc: 0.8710\n",
      "Epoch 375/500\n",
      "274/274 [==============================] - 0s 371us/step - loss: 0.1629 - acc: 0.9380 - val_loss: 0.3539 - val_acc: 0.9032\n",
      "Epoch 376/500\n",
      "274/274 [==============================] - 0s 413us/step - loss: 0.1314 - acc: 0.9526 - val_loss: 0.2971 - val_acc: 0.9032\n",
      "Epoch 377/500\n",
      "274/274 [==============================] - 0s 408us/step - loss: 0.1311 - acc: 0.9489 - val_loss: 0.2567 - val_acc: 0.9032\n",
      "Epoch 378/500\n",
      "274/274 [==============================] - 0s 370us/step - loss: 0.1384 - acc: 0.9453 - val_loss: 0.3934 - val_acc: 0.8710\n",
      "Epoch 379/500\n",
      "274/274 [==============================] - 0s 392us/step - loss: 0.1260 - acc: 0.9562 - val_loss: 0.4000 - val_acc: 0.9032\n",
      "Epoch 380/500\n",
      "274/274 [==============================] - 0s 350us/step - loss: 0.1207 - acc: 0.9526 - val_loss: 0.1855 - val_acc: 0.9032\n",
      "Epoch 381/500\n",
      "274/274 [==============================] - 0s 382us/step - loss: 0.1453 - acc: 0.9307 - val_loss: 0.3601 - val_acc: 0.8710\n",
      "Epoch 382/500\n",
      "274/274 [==============================] - 0s 339us/step - loss: 0.1317 - acc: 0.9489 - val_loss: 0.3358 - val_acc: 0.9032\n",
      "Epoch 383/500\n",
      "274/274 [==============================] - 0s 373us/step - loss: 0.1177 - acc: 0.9635 - val_loss: 0.4949 - val_acc: 0.9032\n",
      "Epoch 384/500\n",
      "274/274 [==============================] - 0s 422us/step - loss: 0.1215 - acc: 0.9526 - val_loss: 0.5900 - val_acc: 0.8710\n",
      "Epoch 385/500\n",
      "274/274 [==============================] - 0s 398us/step - loss: 0.1892 - acc: 0.9124 - val_loss: 0.2668 - val_acc: 0.8710\n",
      "Epoch 386/500\n",
      "274/274 [==============================] - 0s 441us/step - loss: 0.1490 - acc: 0.9307 - val_loss: 0.2710 - val_acc: 0.8710\n",
      "Epoch 387/500\n",
      "274/274 [==============================] - 0s 491us/step - loss: 0.1314 - acc: 0.9489 - val_loss: 0.3396 - val_acc: 0.9032\n",
      "Epoch 388/500\n",
      "274/274 [==============================] - 0s 416us/step - loss: 0.1297 - acc: 0.9526 - val_loss: 0.5032 - val_acc: 0.8710\n",
      "Epoch 389/500\n",
      "274/274 [==============================] - 0s 462us/step - loss: 0.1255 - acc: 0.9416 - val_loss: 0.4297 - val_acc: 0.9032\n",
      "Epoch 390/500\n",
      "274/274 [==============================] - 0s 411us/step - loss: 0.3636 - acc: 0.9015 - val_loss: 0.1500 - val_acc: 0.9032\n",
      "Epoch 391/500\n",
      "274/274 [==============================] - 0s 374us/step - loss: 0.1533 - acc: 0.9343 - val_loss: 0.1220 - val_acc: 0.9032\n",
      "Epoch 392/500\n",
      "274/274 [==============================] - 0s 377us/step - loss: 0.1328 - acc: 0.9562 - val_loss: 0.2336 - val_acc: 0.8710\n",
      "Epoch 393/500\n",
      "274/274 [==============================] - 0s 399us/step - loss: 0.1297 - acc: 0.9489 - val_loss: 0.2216 - val_acc: 0.8710\n",
      "Epoch 394/500\n",
      "274/274 [==============================] - 0s 388us/step - loss: 0.1273 - acc: 0.9453 - val_loss: 0.3788 - val_acc: 0.8710\n",
      "Epoch 395/500\n",
      "274/274 [==============================] - 0s 384us/step - loss: 0.1158 - acc: 0.9635 - val_loss: 0.4441 - val_acc: 0.9032\n",
      "Epoch 396/500\n",
      "274/274 [==============================] - 0s 365us/step - loss: 0.1131 - acc: 0.9672 - val_loss: 0.4838 - val_acc: 0.9032\n",
      "Epoch 397/500\n",
      "274/274 [==============================] - 0s 353us/step - loss: 0.1169 - acc: 0.9635 - val_loss: 0.4843 - val_acc: 0.8710\n",
      "Epoch 398/500\n",
      "274/274 [==============================] - 0s 435us/step - loss: 0.1110 - acc: 0.9635 - val_loss: 0.6012 - val_acc: 0.8710\n",
      "Epoch 399/500\n",
      "274/274 [==============================] - 0s 447us/step - loss: 0.1698 - acc: 0.9161 - val_loss: 0.2789 - val_acc: 0.8710\n",
      "Epoch 400/500\n",
      "274/274 [==============================] - 0s 420us/step - loss: 0.1492 - acc: 0.9416 - val_loss: 0.2195 - val_acc: 0.9355\n",
      "Epoch 401/500\n",
      "274/274 [==============================] - 0s 375us/step - loss: 0.1348 - acc: 0.9526 - val_loss: 0.2527 - val_acc: 0.9032\n",
      "Epoch 402/500\n",
      "274/274 [==============================] - 0s 353us/step - loss: 0.1585 - acc: 0.9453 - val_loss: 0.0486 - val_acc: 0.9677\n",
      "Epoch 403/500\n",
      "274/274 [==============================] - 0s 375us/step - loss: 0.1567 - acc: 0.9307 - val_loss: 0.1738 - val_acc: 0.9677\n",
      "Epoch 404/500\n",
      "274/274 [==============================] - 0s 364us/step - loss: 0.1605 - acc: 0.9416 - val_loss: 0.3517 - val_acc: 0.9032\n",
      "Epoch 405/500\n",
      "274/274 [==============================] - 0s 354us/step - loss: 0.1209 - acc: 0.9562 - val_loss: 0.2878 - val_acc: 0.9032\n",
      "Epoch 406/500\n",
      "274/274 [==============================] - 0s 384us/step - loss: 0.1285 - acc: 0.9489 - val_loss: 0.4725 - val_acc: 0.9032\n",
      "Epoch 407/500\n",
      "274/274 [==============================] - 0s 360us/step - loss: 0.1094 - acc: 0.9672 - val_loss: 0.2892 - val_acc: 0.9032\n",
      "Epoch 408/500\n",
      "274/274 [==============================] - 0s 359us/step - loss: 0.1140 - acc: 0.9599 - val_loss: 0.2926 - val_acc: 0.9032\n",
      "Epoch 409/500\n",
      "274/274 [==============================] - 0s 406us/step - loss: 0.1253 - acc: 0.9489 - val_loss: 0.3463 - val_acc: 0.8710\n",
      "Epoch 410/500\n",
      "274/274 [==============================] - 0s 369us/step - loss: 0.1373 - acc: 0.9453 - val_loss: 0.4806 - val_acc: 0.8710\n",
      "Epoch 411/500\n",
      "274/274 [==============================] - 0s 420us/step - loss: 0.1184 - acc: 0.9635 - val_loss: 0.4751 - val_acc: 0.9032\n",
      "Epoch 412/500\n",
      "274/274 [==============================] - 0s 407us/step - loss: 0.1098 - acc: 0.9599 - val_loss: 0.6198 - val_acc: 0.8710\n",
      "Epoch 413/500\n",
      "274/274 [==============================] - 0s 388us/step - loss: 0.0993 - acc: 0.9672 - val_loss: 0.2013 - val_acc: 0.9355\n",
      "Epoch 414/500\n",
      "274/274 [==============================] - 0s 370us/step - loss: 0.1807 - acc: 0.9234 - val_loss: 0.0652 - val_acc: 0.9677\n",
      "Epoch 415/500\n",
      "274/274 [==============================] - 0s 455us/step - loss: 0.1563 - acc: 0.9234 - val_loss: 0.2604 - val_acc: 0.9355\n",
      "Epoch 416/500\n",
      "274/274 [==============================] - 0s 395us/step - loss: 0.1210 - acc: 0.9453 - val_loss: 0.4460 - val_acc: 0.9032\n",
      "Epoch 417/500\n",
      "274/274 [==============================] - 0s 404us/step - loss: 0.1161 - acc: 0.9672 - val_loss: 0.5977 - val_acc: 0.8710\n",
      "Epoch 418/500\n",
      "274/274 [==============================] - 0s 388us/step - loss: 0.1582 - acc: 0.9307 - val_loss: 0.4577 - val_acc: 0.8710\n",
      "Epoch 419/500\n",
      "274/274 [==============================] - 0s 350us/step - loss: 0.1276 - acc: 0.9526 - val_loss: 0.3637 - val_acc: 0.9032\n",
      "Epoch 420/500\n",
      "274/274 [==============================] - 0s 393us/step - loss: 0.1188 - acc: 0.9562 - val_loss: 0.4276 - val_acc: 0.9032\n",
      "Epoch 421/500\n",
      "274/274 [==============================] - 0s 371us/step - loss: 0.1258 - acc: 0.9562 - val_loss: 0.2454 - val_acc: 0.9355\n",
      "Epoch 422/500\n",
      "274/274 [==============================] - 0s 420us/step - loss: 0.1172 - acc: 0.9526 - val_loss: 0.1514 - val_acc: 0.9677\n",
      "Epoch 423/500\n",
      "274/274 [==============================] - 0s 452us/step - loss: 0.1290 - acc: 0.9489 - val_loss: 0.3852 - val_acc: 0.9032\n",
      "Epoch 424/500\n",
      "274/274 [==============================] - 0s 402us/step - loss: 0.4075 - acc: 0.8759 - val_loss: 0.1291 - val_acc: 0.9355\n",
      "Epoch 425/500\n",
      "274/274 [==============================] - 0s 480us/step - loss: 0.2271 - acc: 0.8905 - val_loss: 0.1188 - val_acc: 0.9032\n",
      "Epoch 426/500\n",
      "274/274 [==============================] - 0s 378us/step - loss: 0.1859 - acc: 0.9380 - val_loss: 0.0915 - val_acc: 0.9355\n",
      "Epoch 427/500\n",
      "274/274 [==============================] - 0s 382us/step - loss: 0.1518 - acc: 0.9380 - val_loss: 0.0732 - val_acc: 0.9677\n",
      "Epoch 428/500\n",
      "274/274 [==============================] - 0s 402us/step - loss: 0.1448 - acc: 0.9489 - val_loss: 0.1590 - val_acc: 0.9032\n",
      "Epoch 429/500\n",
      "274/274 [==============================] - 0s 412us/step - loss: 0.1348 - acc: 0.9635 - val_loss: 0.1538 - val_acc: 0.9032\n",
      "Epoch 430/500\n",
      "274/274 [==============================] - 0s 416us/step - loss: 0.1423 - acc: 0.9453 - val_loss: 0.1060 - val_acc: 0.9032\n",
      "Epoch 431/500\n",
      "274/274 [==============================] - 0s 369us/step - loss: 0.1285 - acc: 0.9635 - val_loss: 0.2048 - val_acc: 0.8710\n",
      "Epoch 432/500\n",
      "274/274 [==============================] - 0s 395us/step - loss: 0.1372 - acc: 0.9453 - val_loss: 0.2327 - val_acc: 0.8710\n",
      "Epoch 433/500\n",
      "274/274 [==============================] - 0s 438us/step - loss: 0.1297 - acc: 0.9562 - val_loss: 0.1168 - val_acc: 0.9032\n",
      "Epoch 434/500\n",
      "274/274 [==============================] - 0s 420us/step - loss: 0.1121 - acc: 0.9708 - val_loss: 0.1952 - val_acc: 0.8710\n",
      "Epoch 435/500\n",
      "274/274 [==============================] - 0s 427us/step - loss: 0.1096 - acc: 0.9599 - val_loss: 0.2486 - val_acc: 0.8710\n",
      "Epoch 436/500\n",
      "274/274 [==============================] - 0s 478us/step - loss: 0.1443 - acc: 0.9416 - val_loss: 0.3809 - val_acc: 0.8710\n",
      "Epoch 437/500\n",
      "274/274 [==============================] - 0s 438us/step - loss: 0.1289 - acc: 0.9562 - val_loss: 0.2281 - val_acc: 0.8710\n",
      "Epoch 438/500\n",
      "274/274 [==============================] - 0s 481us/step - loss: 0.1143 - acc: 0.9599 - val_loss: 0.2708 - val_acc: 0.9032\n",
      "Epoch 439/500\n",
      "274/274 [==============================] - 0s 419us/step - loss: 0.1222 - acc: 0.9489 - val_loss: 0.2107 - val_acc: 0.8710\n",
      "Epoch 440/500\n",
      "274/274 [==============================] - 0s 440us/step - loss: 0.1053 - acc: 0.9708 - val_loss: 0.3147 - val_acc: 0.8710\n",
      "Epoch 441/500\n",
      "274/274 [==============================] - 0s 395us/step - loss: 0.1115 - acc: 0.9672 - val_loss: 0.4104 - val_acc: 0.8710\n",
      "Epoch 442/500\n",
      "274/274 [==============================] - 0s 426us/step - loss: 0.1226 - acc: 0.9416 - val_loss: 0.2958 - val_acc: 0.8710\n",
      "Epoch 443/500\n",
      "274/274 [==============================] - 0s 351us/step - loss: 0.1079 - acc: 0.9562 - val_loss: 0.3570 - val_acc: 0.8710\n",
      "Epoch 444/500\n",
      "274/274 [==============================] - 0s 366us/step - loss: 0.1133 - acc: 0.9599 - val_loss: 0.3916 - val_acc: 0.8710\n",
      "Epoch 445/500\n",
      "274/274 [==============================] - 0s 373us/step - loss: 0.1014 - acc: 0.9635 - val_loss: 0.3098 - val_acc: 0.8710\n",
      "Epoch 446/500\n",
      "274/274 [==============================] - 0s 432us/step - loss: 0.1018 - acc: 0.9599 - val_loss: 0.4815 - val_acc: 0.8710\n",
      "Epoch 447/500\n",
      "274/274 [==============================] - 0s 372us/step - loss: 0.1169 - acc: 0.9562 - val_loss: 0.1150 - val_acc: 0.9032\n",
      "Epoch 448/500\n",
      "274/274 [==============================] - 0s 369us/step - loss: 0.3321 - acc: 0.8796 - val_loss: 0.0840 - val_acc: 0.9032\n",
      "Epoch 449/500\n",
      "274/274 [==============================] - 0s 412us/step - loss: 0.1809 - acc: 0.9051 - val_loss: 0.3038 - val_acc: 0.8710\n",
      "Epoch 450/500\n",
      "274/274 [==============================] - 0s 459us/step - loss: 0.1613 - acc: 0.9453 - val_loss: 0.3373 - val_acc: 0.8065\n",
      "Epoch 451/500\n",
      "274/274 [==============================] - 0s 439us/step - loss: 0.1601 - acc: 0.9270 - val_loss: 0.1276 - val_acc: 0.9677\n",
      "Epoch 452/500\n",
      "274/274 [==============================] - 0s 376us/step - loss: 0.1657 - acc: 0.9307 - val_loss: 0.0172 - val_acc: 1.0000\n",
      "Epoch 453/500\n",
      "274/274 [==============================] - 0s 368us/step - loss: 0.1389 - acc: 0.9380 - val_loss: 0.1090 - val_acc: 0.9677\n",
      "Epoch 454/500\n",
      "274/274 [==============================] - 0s 374us/step - loss: 0.1264 - acc: 0.9635 - val_loss: 0.1237 - val_acc: 0.9677\n",
      "Epoch 455/500\n",
      "274/274 [==============================] - 0s 398us/step - loss: 0.1517 - acc: 0.9380 - val_loss: 0.2088 - val_acc: 0.8710\n",
      "Epoch 456/500\n",
      "274/274 [==============================] - 0s 363us/step - loss: 0.1146 - acc: 0.9672 - val_loss: 0.3030 - val_acc: 0.8710\n",
      "Epoch 457/500\n",
      "274/274 [==============================] - 0s 360us/step - loss: 0.1036 - acc: 0.9599 - val_loss: 0.1759 - val_acc: 0.9032\n",
      "Epoch 458/500\n",
      "274/274 [==============================] - 0s 390us/step - loss: 0.0998 - acc: 0.9708 - val_loss: 0.1081 - val_acc: 0.9355\n",
      "Epoch 459/500\n",
      "274/274 [==============================] - 0s 376us/step - loss: 0.1294 - acc: 0.9526 - val_loss: 0.2276 - val_acc: 0.9032\n",
      "Epoch 460/500\n",
      "274/274 [==============================] - 0s 383us/step - loss: 0.0981 - acc: 0.9672 - val_loss: 0.2966 - val_acc: 0.8710\n",
      "Epoch 461/500\n",
      "274/274 [==============================] - 0s 361us/step - loss: 0.1005 - acc: 0.9635 - val_loss: 0.4414 - val_acc: 0.8710\n",
      "Epoch 462/500\n",
      "274/274 [==============================] - 0s 379us/step - loss: 0.0966 - acc: 0.9745 - val_loss: 0.2652 - val_acc: 0.9032\n",
      "Epoch 463/500\n",
      "274/274 [==============================] - 0s 383us/step - loss: 0.1001 - acc: 0.9599 - val_loss: 0.2547 - val_acc: 0.8710\n",
      "Epoch 464/500\n",
      "274/274 [==============================] - 0s 385us/step - loss: 0.0990 - acc: 0.9635 - val_loss: 0.2581 - val_acc: 0.9032\n",
      "Epoch 465/500\n",
      "274/274 [==============================] - 0s 366us/step - loss: 0.0964 - acc: 0.9708 - val_loss: 0.2368 - val_acc: 0.9032\n",
      "Epoch 466/500\n",
      "274/274 [==============================] - 0s 361us/step - loss: 0.0947 - acc: 0.9708 - val_loss: 0.2029 - val_acc: 0.8710\n",
      "Epoch 467/500\n",
      "274/274 [==============================] - 0s 386us/step - loss: 0.1435 - acc: 0.9416 - val_loss: 0.1872 - val_acc: 0.8710\n",
      "Epoch 468/500\n",
      "274/274 [==============================] - 0s 398us/step - loss: 0.1215 - acc: 0.9599 - val_loss: 0.2294 - val_acc: 0.9032\n",
      "Epoch 469/500\n",
      "274/274 [==============================] - 0s 375us/step - loss: 0.1100 - acc: 0.9526 - val_loss: 0.2901 - val_acc: 0.8710\n",
      "Epoch 470/500\n",
      "274/274 [==============================] - 0s 404us/step - loss: 0.1058 - acc: 0.9562 - val_loss: 0.3779 - val_acc: 0.8710\n",
      "Epoch 471/500\n",
      "274/274 [==============================] - 0s 453us/step - loss: 0.0926 - acc: 0.9708 - val_loss: 0.1151 - val_acc: 0.9677\n",
      "Epoch 472/500\n",
      "274/274 [==============================] - 0s 409us/step - loss: 0.1289 - acc: 0.9599 - val_loss: 0.0726 - val_acc: 0.9677\n",
      "Epoch 473/500\n",
      "274/274 [==============================] - 0s 340us/step - loss: 0.4396 - acc: 0.7920 - val_loss: 0.0947 - val_acc: 0.9355\n",
      "Epoch 474/500\n",
      "274/274 [==============================] - 0s 364us/step - loss: 0.2831 - acc: 0.8394 - val_loss: 0.1456 - val_acc: 0.8387\n",
      "Epoch 475/500\n",
      "274/274 [==============================] - 0s 364us/step - loss: 0.2301 - acc: 0.8577 - val_loss: 0.1543 - val_acc: 0.8710\n",
      "Epoch 476/500\n",
      "274/274 [==============================] - 0s 375us/step - loss: 0.2108 - acc: 0.9015 - val_loss: 0.1696 - val_acc: 0.9355\n",
      "Epoch 477/500\n",
      "274/274 [==============================] - 0s 431us/step - loss: 0.1919 - acc: 0.9088 - val_loss: 0.1526 - val_acc: 0.9677\n",
      "Epoch 478/500\n",
      "274/274 [==============================] - 0s 395us/step - loss: 0.1704 - acc: 0.9234 - val_loss: 0.3240 - val_acc: 0.9032\n",
      "Epoch 479/500\n",
      "274/274 [==============================] - 0s 355us/step - loss: 0.1542 - acc: 0.9307 - val_loss: 0.3490 - val_acc: 0.8710\n",
      "Epoch 480/500\n",
      "274/274 [==============================] - 0s 371us/step - loss: 0.1457 - acc: 0.9453 - val_loss: 0.2455 - val_acc: 0.8710\n",
      "Epoch 481/500\n",
      "274/274 [==============================] - 0s 439us/step - loss: 0.1361 - acc: 0.9489 - val_loss: 0.3146 - val_acc: 0.8710\n",
      "Epoch 482/500\n",
      "274/274 [==============================] - 0s 400us/step - loss: 0.1277 - acc: 0.9489 - val_loss: 0.2483 - val_acc: 0.8710\n",
      "Epoch 483/500\n",
      "274/274 [==============================] - 0s 374us/step - loss: 0.1385 - acc: 0.9416 - val_loss: 0.1290 - val_acc: 0.9677\n",
      "Epoch 484/500\n",
      "274/274 [==============================] - 0s 369us/step - loss: 0.1381 - acc: 0.9526 - val_loss: 0.2156 - val_acc: 0.8710\n",
      "Epoch 485/500\n",
      "274/274 [==============================] - 0s 355us/step - loss: 0.1247 - acc: 0.9599 - val_loss: 0.2792 - val_acc: 0.8710\n",
      "Epoch 486/500\n",
      "274/274 [==============================] - 0s 425us/step - loss: 0.1271 - acc: 0.9526 - val_loss: 0.2410 - val_acc: 0.8710\n",
      "Epoch 487/500\n",
      "274/274 [==============================] - 0s 439us/step - loss: 0.1287 - acc: 0.9672 - val_loss: 0.3334 - val_acc: 0.8710\n",
      "Epoch 488/500\n",
      "274/274 [==============================] - 0s 409us/step - loss: 0.1207 - acc: 0.9526 - val_loss: 0.2586 - val_acc: 0.8710\n",
      "Epoch 489/500\n",
      "274/274 [==============================] - 0s 433us/step - loss: 0.1160 - acc: 0.9562 - val_loss: 0.3227 - val_acc: 0.8710\n",
      "Epoch 490/500\n",
      "274/274 [==============================] - 0s 412us/step - loss: 0.1085 - acc: 0.9599 - val_loss: 0.2141 - val_acc: 0.8710\n",
      "Epoch 491/500\n",
      "274/274 [==============================] - 0s 447us/step - loss: 0.1044 - acc: 0.9672 - val_loss: 0.2844 - val_acc: 0.8710\n",
      "Epoch 492/500\n",
      "274/274 [==============================] - 0s 422us/step - loss: 0.0962 - acc: 0.9672 - val_loss: 0.3089 - val_acc: 0.8710\n",
      "Epoch 493/500\n",
      "274/274 [==============================] - 0s 376us/step - loss: 0.1005 - acc: 0.9635 - val_loss: 0.4227 - val_acc: 0.8710\n",
      "Epoch 494/500\n",
      "274/274 [==============================] - 0s 371us/step - loss: 0.1004 - acc: 0.9745 - val_loss: 0.3074 - val_acc: 0.8710\n",
      "Epoch 495/500\n",
      "274/274 [==============================] - 0s 374us/step - loss: 0.0998 - acc: 0.9599 - val_loss: 0.3613 - val_acc: 0.9032\n",
      "Epoch 496/500\n",
      "274/274 [==============================] - 0s 377us/step - loss: 0.1128 - acc: 0.9562 - val_loss: 0.5284 - val_acc: 0.8710\n",
      "Epoch 497/500\n",
      "274/274 [==============================] - 0s 352us/step - loss: 0.1813 - acc: 0.9234 - val_loss: 0.4738 - val_acc: 0.8710\n",
      "Epoch 498/500\n",
      "274/274 [==============================] - 0s 400us/step - loss: 0.1486 - acc: 0.9416 - val_loss: 0.3583 - val_acc: 0.8710\n",
      "Epoch 499/500\n",
      "274/274 [==============================] - 0s 357us/step - loss: 0.1124 - acc: 0.9526 - val_loss: 0.2984 - val_acc: 0.8710\n",
      "Epoch 500/500\n",
      "274/274 [==============================] - 0s 355us/step - loss: 0.1206 - acc: 0.9416 - val_loss: 0.2078 - val_acc: 0.8710\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "covid = [0., 1]\n",
    "covid = np.array(covid)\n",
    "nocovid = [1, 0.]\n",
    "nocovid = np.array(nocovid)\n",
    "\n",
    "train = np.ones(shape=(305,32, 16))\n",
    "ytrain = np.ones(shape=(305,2))\n",
    "i = 1\n",
    "for i in range(1, 170): # 169\n",
    "    x = np.load(\"../autodl-tmp/capsule108/covid/covid\" + str(i) + \".npy\")\n",
    "    # train[i-1] = np.expand_dims((np.mean(x,axis= 0)),0) #weizhishi  0 - 168\n",
    "    train[i-1] = np.max(x,0)\n",
    "    ytrain[i-1] = covid\n",
    "\n",
    "    i = i + 1\n",
    "for i2 in range(1, 61): #60\n",
    "    x = np.load(\"../autodl-tmp/capsule108/cap/cap\" + str(i2) + \".npy\")\n",
    "    # train[i2+168] = np.expand_dims((np.mean(x,axis= 0)),0)\n",
    "    train[i2+168] = np.max(x,0)\n",
    "    ytrain[i2+168] =nocovid\n",
    "\n",
    "    i2 = i2 +1\n",
    "for i3 in range(1, 77): # 76\n",
    "    x = np.load(\"../autodl-tmp/capsule108/normal/normal\" + str(i3) + \".npy\")\n",
    "    # train[i3+228] =np.expand_dims((np.mean(x,axis= 0)),0)\n",
    "    train[i3+228] = np.max(x,0)\n",
    "    ytrain[i3+228] = nocovid\n",
    "\n",
    "    i3 = i3 +1\n",
    "# print(train)\n",
    "# print(ytrain)\n",
    "#\n",
    "index = [i for i in range(len(train))]\n",
    "# np.random.shuffle(index)\n",
    "# x_train = train[index]\n",
    "# y_train = ytrain[index]\n",
    "x_train = train\n",
    "y_train = ytrain\n",
    "import keras\n",
    "import numpy\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "from keras import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers import *\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class next(Layer):\n",
    "    def __init__(self, x):\n",
    "        super().__init__()\n",
    "        self.x = x\n",
    "\n",
    "    def call(self, tensor):\n",
    "        out = tf.expand_dims(tensor, 2)\n",
    "        out2 = tf.expand_dims(out, 2)\n",
    "\n",
    "        # out_f = tf.reshape(out3,shape=(1,32,16))\n",
    "        return out2\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (None,110, 1, 1)\n",
    "\n",
    "class max(Layer):\n",
    "    def __init__(self, x):\n",
    "        super().__init__()\n",
    "        self.x = x\n",
    "\n",
    "    def call(self, y):\n",
    "        mul = self.x * y\n",
    "        out3 = tf.reduce_max(mul, 1, keep_dims=False)\n",
    "        out4 = tf.reduce_mean(mul, 1, keep_dims=False)\n",
    "        out5 = 0.5*(out4+out3)\n",
    "        return out5\n",
    "        # return out3\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (None, 32, 16)\n",
    "\n",
    "\n",
    "\n",
    "input_image = np.ones((1,108,32,16))\n",
    "# input_tensor1 = Input(shape=(108, 32, 16))\n",
    "# input1 = reshape((1,120,32,16))(input_tensor1)\n",
    "# squeeze = GlobalAveragePooling2D(data_format='channels_first')(input_tensor1)\n",
    "# fullayer = Dense(7,activation=\"relu\")(squeeze)\n",
    "# extract = Dense(108, activation='sigmoid')(fullayer)\n",
    "# 1*110 \n",
    "# quanzhong = next(1)(extract)\n",
    "# avg = max(input_tensor1)(quanzhong)\n",
    "input_tensor1 = Input(shape=(32,16))\n",
    "# x2 = Flatten()(input_tensor)\n",
    "# x2 = Dense(256,activation = 'relu')(x2)\n",
    "fla = Flatten()(input_tensor1)\n",
    "# fla = Flatten()(avg)\n",
    "x1 = Dense(256, activation='relu')(fla)\n",
    "x2 = Dense(128, activation='relu')(x1)\n",
    "x3 = Dense(32, activation='relu')(x2)\n",
    "out_fi = Dense(2, activation='softmax')(x3)\n",
    "model1 = Model(input_tensor1, out_fi)\n",
    "model1.summary()\n",
    "\n",
    "\n",
    "from keras import optimizers\n",
    "from keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "opt = optimizers.Adam(lr=0.001)\n",
    "\n",
    "model1.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=['accuracy']) #adadelta\n",
    "\n",
    "batch_size = 16\n",
    "epochs = 500\n",
    "history = model1.fit(\n",
    "        [x_train], [y_train],\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        # shuffle=True,\n",
    "        validation_split= 0.1,\n",
    ")\n",
    "mp = \"../mean621_noweight_model.h5\" #max16 0.885\n",
    "# model1.save(mp)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# # # import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebb098c-04cc-4412-aacd-25e00339112a",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "x_c = np.ones(shape=(108,32, 16))\n",
    "a=0\n",
    "for i in range(1, 170): # 169\n",
    "    x = np.load(\"../autodl-tmp/capsuleall3216/covid/covidmap\" + str(i) + \".npy\")\n",
    "    all_number = x.shape[0]\n",
    "    zhongjiang = int(all_number/2)\n",
    "    for index in range(int(zhongjiang)-54,(zhongjiang)): #weizhishi  0 - 168\n",
    "        x_c[a] = x[index]\n",
    "        a= a+1\n",
    "\n",
    "    for index in range(zhongjiang,zhongjiang+54): #weizhishi  0 - 168\n",
    "        x_c[a] = x[index]\n",
    "        a= a+1\n",
    "    a = 0\n",
    "    np.save('../autodl-tmp/capsule108/covid/covid'+str(i), x_c)\n",
    "    print('ok',i)\n",
    "    i = i + 1\n",
    "for i2 in range(1, 61): #60\n",
    "    x = np.load(\"../autodl-tmp/capsuleall3216/cap/capmap\" + str(i2) + \".npy\")\n",
    "    all_number = x.shape[0]\n",
    "    zhongjiang = int(all_number/2)\n",
    "    for index in range(int(zhongjiang)-54,(zhongjiang)): #weizhishi  0 - 168\n",
    "        x_c[a] = x[index]\n",
    "        a= a+1\n",
    "\n",
    "    for index in range(zhongjiang,zhongjiang+54): #weizhishi  0 - 168\n",
    "        x_c[a] = x[index]\n",
    "        a= a+1\n",
    "    a = 0\n",
    "    np.save('../autodl-tmp/capsule108/cap/cap'+str(i2), x_c)\n",
    "    print('ok',i2)\n",
    "    i2 = i2 + 1\n",
    "for i3 in range(1, 77): # 76\n",
    "    x = np.load(\"../autodl-tmp/capsuleall3216/normal/normalmap\" + str(i3) + \".npy\")\n",
    "    all_number = x.shape[0]\n",
    "    zhongjiang = int(all_number/2)\n",
    "    for index in range(int(zhongjiang)-54,(zhongjiang)): #weizhishi  0 - 168\n",
    "        x_c[a] = x[index]\n",
    "        a= a+1\n",
    "\n",
    "    for index in range(zhongjiang,zhongjiang+54): #weizhishi  0 - 168\n",
    "        x_c[a] = x[index]\n",
    "        a= a+1\n",
    "    \n",
    "    print('ok',i3)\n",
    "    a = 0\n",
    "    np.save('../autodl-tmp/capsule108/normal/normal'+str(i3), x_c)\n",
    "    i3 = i3 + 1\n",
    "# print(train)\n",
    "# print(ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd40952-979f-4e79-bdc0-6deb0f8eb705",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from keras.layers import *\n",
    "from keras.models import Model\n",
    "import numpy\n",
    "input_tensor = Input(shape=(32,16))\n",
    "x2 = Flatten()(input_tensor)\n",
    "x2 = Dense(256,activation = 'relu')(x2)\n",
    "x2 = Dense(128,activation = 'relu')(x2)\n",
    "x2 = Dense(32,activation = 'relu')(x2)\n",
    "out2 = Dense(2, activation = 'softmax')(x2)\n",
    "model2 = Model(input_tensor,out2)\n",
    "model2.load_weights('binary-max-v4.h5')\n",
    "a = []\n",
    "nocovid = 0\n",
    "for i in range(1,170):\n",
    "    path = '../autodl-tmp/capsuelall3216/covid/covidmap'+str(i)+'.npy'\n",
    "    y = numpy.load(path)\n",
    "    y1 = numpy.max(y,0)\n",
    "    # y2 = numpy.mean(y,0)\n",
    "    y4 = numpy.zeros((1,32,16))\n",
    "    # y4[0] = 0.5*(y1 + y2) 45 73\n",
    "    y4[0] = y1\n",
    "    x = model2.predict(y4)\n",
    "    if x[0][1] >0.5:\n",
    "        nocovid+=1\n",
    "        a.append(i)\n",
    "        print(x)\n",
    "print(nocovid,a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b8a06d-3a40-4487-8977-c72d8984235d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a52e482-3d41-4a64-b2ef-385a20958cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylab\n",
    "import torch\n",
    "from keras import backend as K\n",
    "from keras.layers import Layer\n",
    "from keras import activations\n",
    "from keras import utils\n",
    "from keras.models import Model\n",
    "from keras.layers import *\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import optimizers\n",
    "from keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pydicom\n",
    "import cv2\n",
    "from lungmask import mask  # lung segmentation model\n",
    "import SimpleITK as sitk\n",
    "import matplotlib\n",
    "# Set the path based on your data directory\n",
    "data_path = r'autodl-nas/covid/P005'\n",
    "# Set the cut-off probability for the classification output (Default : 0.5)\n",
    "cutoff = 0.5\n",
    "onepic = 0\n",
    "K.set_image_data_format('channels_last')\n",
    "qiepian_kaishi=1\n",
    "qiepian_jieshu=133\n",
    "# model1 \n",
    "# batch_size = 16\n",
    "# epochs= 100\n",
    "# learn_rate = 0.0001\n",
    "\n",
    "# model2\n",
    "# batch_size = 16\n",
    "# epochs= 500\n",
    "# learn_rate = 0.001\n",
    "\n",
    "def squash(x, axis=-1):\n",
    "    s_squared_norm = K.sum(K.square(x), axis, keepdims=True) + K.epsilon() # epsilon0.001\n",
    "    scale = K.sqrt(s_squared_norm) / (1 + s_squared_norm)\n",
    "    return scale * x\n",
    "\n",
    "\n",
    "def softmax(x, axis=-1):\n",
    "    ex = K.exp(x - K.max(x, axis=axis, keepdims=True))\n",
    "    return ex / K.sum(ex, axis=axis, keepdims=True)\n",
    "\n",
    "\n",
    "def margin_loss(y_true, y_pred):\n",
    "    lamb, margin = 0.5, 0.1\n",
    "    return K.sum((y_true * K.square(K.relu(1 - margin - y_pred)) + lamb * (\n",
    "            1 - y_true) * K.square(K.relu(y_pred - margin))), axis=-1)\n",
    "\n",
    "from torch import nn\n",
    "from torch.nn import init\n",
    "\n",
    "\n",
    "\n",
    "class Capsule(Layer):\n",
    "\n",
    "    def __init__(self,\n",
    "                 num_capsule, #  16\n",
    "                 dim_capsule, #  32\n",
    "                 routings=3,\n",
    "                 share_weights=True,\n",
    "                 activation='squash',\n",
    "                 **kwargs):\n",
    "        super(Capsule, self).__init__(**kwargs)\n",
    "        self.num_capsule = num_capsule\n",
    "        self.dim_capsule = dim_capsule\n",
    "        self.routings = routings\n",
    "        self.share_weights = share_weights\n",
    "        if activation == 'squash':\n",
    "            self.activation = squash\n",
    "        else:\n",
    "            self.activation = activations.get(activation)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'num_capsule': self.num_capsule,\n",
    "            'dim_capsule': self.dim_capsule,\n",
    "            'routings': self.routings,\n",
    "            'share_weight': self.share_weights,\n",
    "\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        input_dim_capsule = input_shape[-1]\n",
    "        if self.share_weights:\n",
    "            self.kernel = self.add_weight(\n",
    "                name='capsule_kernel',\n",
    "                shape=(1, input_dim_capsule,\n",
    "                       self.num_capsule * self.dim_capsule),\n",
    "                initializer='glorot_uniform',\n",
    "                trainable=True)\n",
    "        else:\n",
    "            input_num_capsule = input_shape[-2]\n",
    "            self.kernel = self.add_weight(\n",
    "                name='capsule_kernel',\n",
    "                shape=(input_num_capsule, input_dim_capsule,\n",
    "                       self.num_capsule * self.dim_capsule),\n",
    "                initializer='glorot_uniform',\n",
    "                trainable=True)\n",
    "\n",
    "    def call(self, inputs):\n",
    "\n",
    "        if self.share_weights:\n",
    "            hat_inputs = K.conv1d(inputs, self.kernel)\n",
    "        else:\n",
    "            hat_inputs = K.local_conv1d(inputs, self.kernel, [1], [1])\n",
    "\n",
    "        batch_size = K.shape(inputs)[0]\n",
    "        input_num_capsule = K.shape(inputs)[1]\n",
    "        hat_inputs = K.reshape(hat_inputs,\n",
    "                               (batch_size, input_num_capsule,\n",
    "                                self.num_capsule, self.dim_capsule))\n",
    "        hat_inputs = K.permute_dimensions(hat_inputs, (0, 2, 1, 3))\n",
    "\n",
    "        b = K.zeros_like(hat_inputs[:, :, :, 0])\n",
    "        for i in range(self.routings):\n",
    "            c = softmax(b, 1)\n",
    "            o = self.activation(keras.backend.batch_dot(c, hat_inputs, [2, 2]))\n",
    "            if i < self.routings - 1:\n",
    "                b = keras.backend.batch_dot(o, hat_inputs, [2, 3])\n",
    "                if K.backend() == 'theano':\n",
    "                    o = K.sum(o, axis=1)\n",
    "\n",
    "        return o\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (None, self.num_capsule, self.dim_capsule)\n",
    "    \n",
    "input_image = Input(shape=(None, None, 1))\n",
    "x = Conv2D(64, (3, 3), activation='relu', trainable=True)(input_image)\n",
    "x = BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros',\n",
    "                       gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones',\n",
    "                       beta_regularizer=None, gamma_regularizer=None, beta_constraint=None, gamma_constraint=None)(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', trainable=True)(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Conv2D(128, (3, 3), activation='relu', trainable=True)(x)\n",
    "x= Conv2D(128, (3, 3), activation='relu', trainable=True)(x) # (116, 126, 126, 64)\n",
    "#\n",
    "x = Reshape((-1, 128))(x)\n",
    "x = Capsule(32, 16)(x)\n",
    "x = Capsule(32, 16)(x)\n",
    "capsule = Capsule(2, 16)(x)\n",
    "output = Lambda(lambda z: K.sqrt(K.sum(K.square(z), 2)))(capsule)\n",
    "\n",
    "model = Model(inputs=[input_image], outputs=[output])\n",
    "# adam = optimizers.Adam(lr=1e-4)\n",
    "# model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "# # model.save_weights(\"model.h5\")\n",
    "model.load_weights('weights-2class-v1-71.h5')\n",
    "input_stage_fe = model.input\n",
    "output_stage_fe = model.layers[-3].output\n",
    "model_fe = Model(input_stage_fe,output_stage_fe)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a404e5c0-0679-40f8-9429-73c6932d8a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "path = '../autodl-tmp/lung/covid/covid1.npy'\n",
    "x = numpy.load(path)\n",
    "print(numpy.all(x[0]==0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e8f71b-024c-4eb1-b691-52db4ea22893",
   "metadata": {},
   "outputs": [],
   "source": [
    "5.17\n",
    "from keras.layers import *\n",
    "from keras.models import Model\n",
    "input_tensor = Input(shape=(32,16))\n",
    "x2 = Flatten()(input_tensor)\n",
    "x2 = Dense(256,activation = 'relu')(x2)\n",
    "x2 = Dense(128,activation = 'relu')(x2)\n",
    "x2 = Dense(32,activation = 'relu')(x2)\n",
    "out2 = Dense(2, activation = 'softmax')(x2)\n",
    "model2 = Model(input_tensor,out2)\n",
    "# model2.load_weights('../autodl-tmp/maxmean_model.h5') \n",
    "model2.load_weights('mean621_108_noweight_model.h5')\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy\n",
    "covid=0\n",
    "cap=0\n",
    "normal=0\n",
    "nocovid=0\n",
    "nocap=0\n",
    "nonormal=0\n",
    "true = numpy.zeros((305,2))\n",
    "pred =numpy.zeros((305,2))\n",
    "zzz = 0\n",
    "for i in range(1,170):\n",
    "    path = '../autodl-tmp/capsule1083216/covid/covidmap'+str(i)+'.npy'\n",
    "    x = numpy.load(path)\n",
    "    # x2 = numpy.zeros((108,256,256,1))\n",
    "    # zhongjian = x.shape[0]/2\n",
    "    # ceshi= 0\n",
    "    # for z in range(zhongjian-54,zhongjian):\n",
    "    #     x2[ceshi]=x[z]\n",
    "    #     ceshi+=1\n",
    "    # for z in range(zhongjian,zhongjian+54):\n",
    "    #     x2[ceshi]=x[z]\n",
    "    #     ceshi+=1\n",
    "    # y = model_fe.predict(x2) #108,32,16,1\n",
    "    out1 = numpy.max(x,0)\n",
    "    out2 = numpy.mean(x,0)\n",
    "    out3 = 0.5*(out1+out2)\n",
    "    c = numpy.zeros((1,32,16))\n",
    "    c[0] = out3\n",
    "    y2 = model2.predict(c)\n",
    "    pred[i-1] = y2\n",
    "    true[i-1] = [0,1]\n",
    "    if y2[0][1]>0.5:\n",
    "        covid+=1\n",
    "    else:\n",
    "        nocovid+=1\n",
    "        print(path)\n",
    "  \n",
    "for i in range(1,77):\n",
    "    path = '../autodl-tmp/capsule1083216/normal/normalmap'+str(i)+'.npy'\n",
    "    x = numpy.load(path)\n",
    "    # y = model_fe.predict(x) #108,32,16,1\n",
    "    out1 = numpy.max(x,0)\n",
    "    out2 = numpy.mean(x,0)\n",
    "    out3 = 0.5*(out1+out2)\n",
    "    c = numpy.zeros((1,32,16))\n",
    "    c[0] = out3\n",
    "    y2 = model2.predict(c)\n",
    "    pred[i+168] = y2\n",
    "    true[i+168] = [1,0]\n",
    "    if y2[0][1]>0.5:\n",
    "        nonormal+=1\n",
    "        print(path)\n",
    "    else:normal+=1\n",
    "    \n",
    "for i in range(1,61):\n",
    "    path = '../autodl-tmp/capsule1083216/cap/capmap'+str(i)+'.npy'\n",
    "    x = numpy.load(path)\n",
    "    # x2 = numpy.zeros((108,256,256,1))\n",
    "    # zhongjian = x.shape[0]/2\n",
    "    # ceshi= 0\n",
    "    # z=0\n",
    "    # for z in range(zhongjian-54,zhongjian):\n",
    "    #     x2[ceshi]=x[z]\n",
    "    #     ceshi+=1\n",
    "    # for z in range(zhongjian,zhongjian+54):\n",
    "    #     x2[ceshi]=x[z]\n",
    "    #     ceshi+=1\n",
    "    # y = model_fe.predict(x2) #108,32,16,1\n",
    "    out1 = numpy.max(x,0)\n",
    "    out2 = numpy.mean(x,0)\n",
    "    out3 = 0.5*(out1+out2)\n",
    "    c = numpy.zeros((1,32,16))\n",
    "    c[0] = out3\n",
    "    y2 = model2.predict(c)\n",
    "    pred[i+244] = y2\n",
    "    true[i+244] = [1,0]\n",
    "    if y2[0][1]>0.5:\n",
    "        nocap+=1\n",
    "        print(path)\n",
    "    else:cap+=1\n",
    "    \n",
    "acc = (305-nocap-nonormal-nocovid)/305\n",
    "\n",
    "Sensitivity = 1-(nocovid/169)\n",
    "\n",
    "Specificity = 1 - (nocap+nonormal)/136\n",
    "import numpy as np\n",
    "# from sklearn import metrics\n",
    "auc = roc_auc_score(true,pred)\n",
    "print(\"acc,Sensitivity,Specificity,auc\",acc,Sensitivity,Specificity,auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d8ea38-92c5-4df4-9ee1-c1f023c2875d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "y= 22984\n",
    "z = numpy.zeros((10000,256,256,1))\n",
    "z2 = numpy.zeros((10000,2))\n",
    "path2 = '../Slice-level-labels.npy'\n",
    "c= numpy.load(path2)\n",
    "index = 0\n",
    "i=0\n",
    "number = 0\n",
    "for i in range(1,170):\n",
    "    path = '../autodl-tmp/lung/covid/covid'+str(i)+'.npy'\n",
    "    x = numpy.load(path)\n",
    "    i2=0\n",
    "    for i2 in range(0,x.shape[0]):\n",
    "        z[index] = x[i2]\n",
    "        z2[index] = c[i-1][i2]\n",
    "        index +=1\n",
    "        number+=1\n",
    "print(number)\n",
    "i=0\n",
    "for i in range(1,55):\n",
    "    path = '../autodl-tmp/lung/cap/cap'+str(i)+'.npy'\n",
    "    x = numpy.load(path)\n",
    "    # y+=x.shape[0]\n",
    "    i2=0\n",
    "    for i2 in range(0,x.shape[0]):\n",
    "        z[index] = x[i2]\n",
    "        index +=1\n",
    "        number+=1\n",
    "print(number)\n",
    "i=0\n",
    "for i in range(1,77):\n",
    "    path = '../autodl-tmp/lung/normal/normal'+str(i)+'.npy'\n",
    "    x = numpy.load(path)\n",
    "    i2 =0\n",
    "    for i2 in range(0,x.shape[0]):\n",
    "        z[index] = x[i2]\n",
    "        z[]\n",
    "        index +=1\n",
    "        number+=1\n",
    "print(number)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa39a0ed-93bc-4f8a-9d72-5be1683827eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "path2 = '../Slice-level-labels.npy'\n",
    "c= numpy.load(path2)\n",
    "index =0\n",
    "for i in range(1,56):\n",
    "    path = '../autodl-tmp/lung/covid/covid'+str(i)+'.npy'\n",
    "    x = numpy.load(path)\n",
    "    i2=0\n",
    "    for i2 in range(0,x.shape[0]):\n",
    "        if c[i-1][i2] == 1:\n",
    "            z2[index][1] =1\n",
    "            index +=1\n",
    "        if c[i-1][i2] == 0:\n",
    "            z2[index][0] =1\n",
    "            index +=1\n",
    "i=0\n",
    "for i in range(1,23):\n",
    "    path = '../autodl-tmp/lung/cap/cap'+str(i)+'.npy'\n",
    "    x = numpy.load(path)\n",
    "    # y+=x.shape[0]\n",
    "    i2=0\n",
    "    for i2 in range(0,x.shape[0]):\n",
    "        if c[i-1][i2] == 1:\n",
    "            z2[index][1] =1\n",
    "            index +=1\n",
    "        if c[i-1][i2] == 0:\n",
    "            z2[index][0] =1\n",
    "            index +=1\n",
    "i=0\n",
    "for i in range(1,77):\n",
    "    path = '../autodl-tmp/lung/normal/normal'+str(i)+'.npy'\n",
    "    x = numpy.load(path)\n",
    "    # y+=x.shape[0]\n",
    "    i2 =0\n",
    "    for i2 in range(0,x.shape[0]):\n",
    "        if c[i-1][i2] == 1:\n",
    "            z2[index][1] =1\n",
    "            index +=1\n",
    "        if c[i-1][i2] == 0:\n",
    "            z2[index][0] =1\n",
    "            index +=1\n",
    "print(numpy.all(z2==0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176f3c8e-ab53-4e4b-8737-f85b1d8304f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "epochs = 100\n",
    "history = model.fit(\n",
    "        [z], [z2],\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        shuffle=True,\n",
    "        # validation_data= ([z],[z2]),\n",
    "        validation_split=0.2,\n",
    "    #validation_split=0.2,\n",
    "    verbose=1\n",
    ")\n",
    "mp = \"capsule5.10.h5\" #max16 0.885\n",
    "model.save(mp)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c490990e-2a9d-4612-8da5-bc0d3b15f2be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea5a26b-c5fe-46f0-965d-6b5e5dfb33c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "covid = [0., 1]\n",
    "covid = np.array(covid)\n",
    "nocovid = [1, 0.]\n",
    "nocovid = np.array(nocovid)\n",
    "\n",
    "ytrain = np.ones(shape=(305, 2))\n",
    "\n",
    "\n",
    "adam = optimizers.Adam(lr=1e-3)\n",
    "model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "batch_size = 305\n",
    "epochs = 500\n",
    "history = model.fit(\n",
    "        [x_train], [y_train],\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        shuffle=True,\n",
    "        validation_data= ([x_train],[y_train]),\n",
    "        # validation_split=0.2,\n",
    "    #validation_split=0.2,\n",
    "    verbose=1\n",
    ")\n",
    "mp = \"../autodl-tmp/feature_model.h5\" #max16 0.885\n",
    "model1.save(mp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d51a880-ab1c-44a5-a55f-f1d28e706481",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "import keras\n",
    "import numpy\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "from keras import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers import *\n",
    "import numpy as np\n",
    "from sklearn.tests.test_base import K\n",
    "from tensorflow import expand_dims\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class next(Layer):\n",
    "    def __init__(self, x):\n",
    "        super().__init__()\n",
    "        self.x = x\n",
    "\n",
    "    def call(self, tensor):\n",
    "        out = tf.expand_dims(tensor, 2)\n",
    "        out2 = tf.expand_dims(out, 2)\n",
    "\n",
    "        # out_f = tf.reshape(out3,shape=(1,32,16))\n",
    "        return out2\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (None,108, 1, 1)\n",
    "\n",
    "class max(Layer):\n",
    "    def __init__(self, x):\n",
    "        super().__init__()\n",
    "        self.x = x\n",
    "\n",
    "    def call(self, y):\n",
    "        mul = self.x * y\n",
    "        out3 = tf.reduce_max(mul, 1, keep_dims=False)\n",
    "\n",
    "        return out3\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (None, 32, 16)\n",
    "\n",
    "\n",
    "# test = np.ones(shape=(1, 108, 32, 16))\n",
    "# test[0] = np.load(\"../autodl-tmp/3.30/covid/covidmap1.npy\")\n",
    "# input_image = np.ones((1,108,32,16))\n",
    "    # input_tensor1 = Input(shape=(108, 32, 16))\n",
    "    # # input1 = reshape((1,120,32,16))(input_tensor1)\n",
    "    # squeeze = GlobalAveragePooling2D(data_format='channels_first')(input_tensor1)\n",
    "    # fullayer = Dense(7, activation=\"relu\")(squeeze)\n",
    "    # extract = Dense(108, activation='sigmoid')(fullayer)\n",
    "    # #1*110 \n",
    "    # quanzhong = next(1)(extract)\n",
    "    # avg = max(input_tensor1)(quanzhong)\n",
    "    # fla = Flatten()(avg)\n",
    "    # x1 = Dense(256, activation='relu')(fla)\n",
    "    # x2 = Dense(128, activation='relu')(x1)\n",
    "    # x3 = Dense(32, activation='relu')(x2)\n",
    "    # out_fi = Dense(2, activation='softmax')(x3)\n",
    "    # model1 = Model(input_tensor1, out_fi)\n",
    "    # model1.summary()\n",
    "\n",
    "model1.load_weights(\"../autodl-tmp/max8_108_model.h5\")\n",
    "\n",
    "# 10 covid 156   16 covid 157   14 covid 158  7 covid 157\n",
    "# model2 = Model(input_tensor1, model1.layers[3].output)\n",
    "# td = model2.predict(test)\n",
    "# print(td)\n",
    "# model3 = Model(input_tensor1, model1.layers[-6].output)\n",
    "# qz = model3.predict(test)\n",
    "# print(qz)\n",
    "all = []\n",
    "covidnumber = []\n",
    "cap_pred = np.ones(shape=(170,2))\n",
    "cap_true = np.ones(shape=(170,2))\n",
    "for i in range(1,61):\n",
    "    test = np.ones(shape=(1, 108, 32, 16))\n",
    "    test[0] = np.load(\"../autodl-tmp/capsule1083216/normal/normalmap\"+str(i)+\".npy\")\n",
    "    c4 = model1.predict(test)\n",
    "    cap_pred[i-1] = c4\n",
    "    cap_true[i-1] = [1,0]\n",
    "    if c4[:,1] > 0.5:\n",
    "        pred= \"covid\"\n",
    "\n",
    "    else:\n",
    "        pred = \"nocovid\"\n",
    "        covidnumber.append(i)\n",
    "    all.append({\"truth\":i,\n",
    "                \"pred\":pred})\n",
    "    print(pred,i)\n",
    "print(all)\n",
    "print(covidnumber)\n",
    "\n",
    "import numpy as np\n",
    "# from sklearn import metrics\n",
    "# fpr, tpr, thresholds = metrics.roc_curve(cap_true,cap_pred, pos_label=1)\n",
    "# s = metrics.auc(fpr, tpr)\n",
    "# print(s)\n",
    "'''\n",
    "[{'truth': 1, 'pred': 'nocovid'}, {'truth': 2, 'pred': 'covid'}, {'truth': 3, 'pred': 'nocovid'}, {'truth': 4, 'pred': 'nocovid'}, {'truth': 5, 'pred': 'nocovid'}, {'truth': 6, 'pred': 'nocovid'}, {'truth': 7, 'pred': 'nocovid'}, {'truth': 8, 'pred': 'nocovid'}, {'truth': 9, 'pred': 'nocovid'}, {'truth': 10, 'pred': 'nocovid'}, {'truth': 11, 'pred': 'nocovid'}, {'truth': 12, 'pred': 'nocovid'}, {'truth': 13, 'pred': 'nocovid'}, {'truth': 14, 'pred': 'nocovid'}, {'truth': 15, 'pred': 'covid'}, {'truth': 16, 'pred': 'nocovid'}, {'truth': 17, 'pred': 'nocovid'}, {'truth': 18, 'pred': 'nocovid'},\n",
    " {'truth': 19, 'pred': 'nocovid'}, {'truth': 20, 'pred': 'nocovid'}, {'truth': 21, 'pred': 'nocovid'}, {'truth': 22, 'pred': 'nocovid'}, {'truth': 23, 'pred': 'nocovid'}, {'truth': 24, 'pred': 'nocovid'}, {'truth': 25, 'pred': 'nocovid'}, {'truth': 26, 'pred': 'nocovid'}, {'truth': 27, 'pred': 'nocovid'}, {'truth': 28, 'pred': 'covid'}, {'truth': 29, 'pred': 'covid'}, {'truth': 30, 'pred': 'nocovid'}, {'truth': 31, 'pred': 'nocovid'}, {'truth': 32, 'pred': 'nocovid'}, {'truth': 33, 'pred': 'covid'}, {'truth': 34, 'pred': 'nocovid'}, {'truth': 35, 'pred': 'covid'}, {'truth': 36, 'pred': 'covid'},\n",
    "  {'truth': 37, 'pred': 'covid'}, {'truth': 38, 'pred': 'nocovid'}, {'truth': 39, 'pred': 'nocovid'}, {'truth': 40, 'pred': 'covid'}, {'truth': 41, 'pred': 'nocovid'}, {'truth': 42, 'pred': 'nocovid'}, {'truth': 43, 'pred': 'nocovid'}, {'truth': 44, 'pred': 'covid'}, {'truth': 45, 'pred': 'covid'}, {'truth': 46, 'pred': 'covid'}, {'truth': 47, 'pred': 'nocovid'}, {'truth': 48, 'pred': 'nocovid'}, {'truth': 49, 'pred': 'nocovid'}, {'truth': 50, 'pred': 'covid'}, {'truth': 51, 'pred': 'nocovid'}, {'truth': 52, 'pred': 'covid'}, {'truth': 53, 'pred': 'nocovid'}, {'truth': 54, 'pred': 'covid'}, {'truth': 55, 'pred': 'covid'}, \n",
    "  {'truth': 56, 'pred': 'covid'}, {'truth': 57, 'pred': 'nocovid'}, {'truth': 58, 'pred': 'covid'}, {'truth': 59, 'pred': 'nocovid'}, {'truth': 60, 'pred': 'covid'}]\n",
    "19\n",
    "'''\n",
    "\n",
    "'''\n",
    "covid 144  false 25\n",
    "'''\n",
    "\n",
    "'''\n",
    "normal 0\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e64cc61-465c-42a5-b512-dbf398dcf7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "import numpy\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "from keras import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers import *\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.tests.test_base import K\n",
    "from tensorflow import expand_dims\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class next(Layer):\n",
    "    def __init__(self, x):\n",
    "        super().__init__()\n",
    "        self.x = x\n",
    "\n",
    "    def call(self, tensor):\n",
    "        out = tf.expand_dims(tensor, 2)\n",
    "        out2 = tf.expand_dims(out, 2)\n",
    "\n",
    "        # out_f = tf.reshape(out3,shape=(1,32,16))\n",
    "        return out2\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (None,108, 1, 1)\n",
    "\n",
    "class max(Layer):\n",
    "    def __init__(self, x):\n",
    "        super().__init__()\n",
    "        self.x = x\n",
    "\n",
    "    def call(self, y):\n",
    "        mul = self.x * y\n",
    "        out3 = tf.reduce_max(mul, 1, keep_dims=False)\n",
    "        out4 = tf.reduce_mean(mul, 1, keep_dims=False)\n",
    "        out5 = 0.5*(out4+out3)\n",
    "        return out5\n",
    "        # return out3\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (None, 32, 16)\n",
    "\n",
    "\n",
    "# test = np.ones(shape=(1, 110, 32, 16))\n",
    "# test[0] = np.load(\"../autodl-tmp/3.30/covid/covidmap1.npy\")\n",
    "input_image = np.ones((1,108,32,16))\n",
    "input_tensor1 = Input(shape=(108, 32, 16))\n",
    "# input1 = reshape((1,120,32,16))(input_tensor1)\n",
    "squeeze = GlobalAveragePooling2D(data_format='channels_first')(input_tensor1)\n",
    "fullayer = Dense(7, activation=\"relu\")(squeeze)\n",
    "extract = Dense(108, activation='sigmoid')(fullayer)\n",
    "#1*110 \n",
    "quanzhong = next(1)(extract)\n",
    "avg = max(input_tensor1)(quanzhong)\n",
    "fla = Flatten()(avg)\n",
    "x1 = Dense(256, activation='relu')(fla)\n",
    "x2 = Dense(128, activation='relu')(x1)\n",
    "x3 = Dense(32, activation='relu')(x2)\n",
    "out_fi = Dense(2, activation='softmax')(x3)\n",
    "model1 = Model(input_tensor1, out_fi)\n",
    "model1.summary()\n",
    "model2 = Model(input_tensor1, model1.layers[4].output)\n",
    "#model1.load_weights(\"../ct_train/max7_108_model4.h5\")\n",
    "#np.resize\n",
    "model1.load_weights(\"../maxmean8_108_model.h5\")\n",
    "# 10 covid 156   16 covid 157   14 covid 158  7 covid 157\n",
    "# model2 = Model(input_tensor1, model1.layers[3].output)\n",
    "# td = model2.predict(test)\n",
    "# print(td)\n",
    "# model3 = Model(input_tensor1, model1.layers[-6].output)\n",
    "# qz = model3.predict(test)\n",
    "# print(qz)\n",
    "all = []\n",
    "covidnumber = []\n",
    "fcovid = 0\n",
    "cap_pred = np.ones(shape=(305,2))\n",
    "cap_true = np.ones(shape=(305,2))\n",
    "for i in range(1,170):\n",
    "    test = np.ones(shape=(1,108, 32, 16))\n",
    "    test[0] = np.load(\"../autodl-tmp/capsule1083216/covid/covidmap\"+str(i)+\".npy\")\n",
    "    c4 = model1.predict(test)\n",
    "    onetime = model2.predict(test)\n",
    "    cap_pred[i-1] = c4\n",
    "    cap_true[i-1] = [0,1]\n",
    "    if c4[:,1] > c4[:,0]:\n",
    "        pred= \"covid\"\n",
    "    else:\n",
    "        pred = \"nocovid\"\n",
    "        covidnumber.append(i)\n",
    "        fcovid+=1\n",
    "    all.append({\"truth\":i,\n",
    "                \"pred\":pred,\n",
    "                \"c4\":c4},)\n",
    "    print(c4)  # [[8.867428e-05 9.999113e-01]]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "all = []\n",
    "covidnumber = []\n",
    "fcap = 0\n",
    "for i in range(1,61):\n",
    "    test = np.ones(shape=(1,108, 32, 16))\n",
    "    test[0] = np.load(\"../autodl-tmp/capsule1083216/cap/capmap\"+str(i)+\".npy\")\n",
    "    c4 = model1.predict(test)\n",
    "    cap_pred[i+168] = c4\n",
    "    cap_true[i+168] = [1,0]\n",
    "    if c4[:,1] > 0.5:\n",
    "        pred= \"covid\"\n",
    "        covidnumber.append(i)\n",
    "        fcap+=1\n",
    "    else:\n",
    "        pred = \"nocovid\"\n",
    "\n",
    "    all.append({\"truth\":i,\n",
    "                \"pred\":pred})\n",
    "    # print(pred,i)\n",
    "print(all)\n",
    "print(covidnumber)\n",
    "print(fcap)\n",
    "\n",
    "all = []\n",
    "covidnumber = []\n",
    "fnormal = 0\n",
    "for i in range(1,77):\n",
    "    test = np.ones(shape=(1,108, 32, 16))\n",
    "    test[0] = np.load(\"../autodl-tmp/capsule1083216/normal/normalmap\"+str(i)+\".npy\")\n",
    "    c4 = model1.predict(test)\n",
    "    cap_pred[i+228] = c4\n",
    "    cap_true[i+228] = [1,0]\n",
    "    if c4[:,1] > 0.7:\n",
    "        pred= \"covid\"\n",
    "        covidnumber.append(i)\n",
    "        fnormal +=1\n",
    "    else:\n",
    "        pred = \"nocovid\"\n",
    "    all.append({\"truth\":i,\n",
    "                \"pred\":pred})\n",
    "    # print(pred,i)\n",
    "print(all)\n",
    "print(covidnumber)\n",
    "\n",
    "acc = (305-fcap-fnormal-fcovid)/305\n",
    "\n",
    "Sensitivity = 1-(fcovid/169)\n",
    "\n",
    "Specificity = 1 - (fcap+fnormal)/136\n",
    "import numpy as np\n",
    "# from sklearn import metrics\n",
    "auc = roc_auc_score(cap_true,cap_pred)\n",
    "print(\"acc,Sensitivity,Specificity,auc\",acc,Sensitivity,Specificity,auc)\n",
    "\n",
    "'''\n",
    "[{'truth': 1, 'pred': 'nocovid'}, {'truth': 2, 'pred': 'covid'}, {'truth': 3, 'pred': 'nocovid'}, {'truth': 4, 'pred': 'nocovid'}, {'truth': 5, 'pred': 'nocovid'}, {'truth': 6, 'pred': 'nocovid'}, {'truth': 7, 'pred': 'nocovid'}, {'truth': 8, 'pred': 'nocovid'}, {'truth': 9, 'pred': 'nocovid'}, {'truth': 10, 'pred': 'nocovid'}, {'truth': 11, 'pred': 'nocovid'}, {'truth': 12, 'pred': 'nocovid'}, {'truth': 13, 'pred': 'nocovid'}, {'truth': 14, 'pred': 'nocovid'}, {'truth': 15, 'pred': 'covid'}, {'truth': 16, 'pred': 'nocovid'}, {'truth': 17, 'pred': 'nocovid'}, {'truth': 18, 'pred': 'nocovid'},\n",
    " {'truth': 19, 'pred': 'nocovid'}, {'truth': 20, 'pred': 'nocovid'}, {'truth': 21, 'pred': 'nocovid'}, {'truth': 22, 'pred': 'nocovid'}, {'truth': 23, 'pred': 'nocovid'}, {'truth': 24, 'pred': 'nocovid'}, {'truth': 25, 'pred': 'nocovid'}, {'truth': 26, 'pred': 'nocovid'}, {'truth': 27, 'pred': 'nocovid'}, {'truth': 28, 'pred': 'covid'}, {'truth': 29, 'pred': 'covid'}, {'truth': 30, 'pred': 'nocovid'}, {'truth': 31, 'pred': 'nocovid'}, {'truth': 32, 'pred': 'nocovid'}, {'truth': 33, 'pred': 'covid'}, {'truth': 34, 'pred': 'nocovid'}, {'truth': 35, 'pred': 'covid'}, {'truth': 36, 'pred': 'covid'},\n",
    "  {'truth': 37, 'pred': 'covid'}, {'truth': 38, 'pred': 'nocovid'}, {'truth': 39, 'pred': 'nocovid'}, {'truth': 40, 'pred': 'covid'}, {'truth': 41, 'pred': 'nocovid'}, {'truth': 42, 'pred': 'nocovid'}, {'truth': 43, 'pred': 'nocovid'}, {'truth': 44, 'pred': 'covid'}, {'truth': 45, 'pred': 'covid'}, {'truth': 46, 'pred': 'covid'}, {'truth': 47, 'pred': 'nocovid'}, {'truth': 48, 'pred': 'nocovid'}, {'truth': 49, 'pred': 'nocovid'}, {'truth': 50, 'pred': 'covid'}, {'truth': 51, 'pred': 'nocovid'}, {'truth': 52, 'pred': 'covid'}, {'truth': 53, 'pred': 'nocovid'}, {'truth': 54, 'pred': 'covid'}, {'truth': 55, 'pred': 'covid'}, \n",
    "  {'truth': 56, 'pred': 'covid'}, {'truth': 57, 'pred': 'nocovid'}, {'truth': 58, 'pred': 'covid'}, {'truth': 59, 'pred': 'nocovid'}, {'truth': 60, 'pred': 'covid'}]\n",
    "19\n",
    "'''\n",
    "\n",
    "'''\n",
    "covid 144  false 25\n",
    "'''\n",
    "\n",
    "'''\n",
    "normal 0\n",
    "'''\n",
    "\n",
    "'''\n",
    "covid nocovid[53, 58, 60, 62, 67, 87, 103, 105, 112, 132, 147, 155, 164]\n",
    "\n",
    "cap covid [2, 7, 15, 27, 28, 34, 36, 37, 40, 44, 45, 46, 50, 52, 54, 55, 56, 58, 60]\n",
    "\n",
    "normal\n",
    "'''\n",
    "\n",
    "'''\n",
    "covid 0  3\n",
    "\n",
    "cap 0  1\n",
    "\n",
    "normal 0  0\n",
    "'''\n",
    "\n",
    "'''\n",
    "0.6 acc,Sensitivity,Specificity,auc 0.9770491803278688 0.9704142011834319 0.9852941176470589 0.9943873999303863\n",
    "'''\n",
    "\n",
    "'''\n",
    "val\n",
    "[{'truth': 1, 'pred': 'covid'}, {'truth': 2, 'pred': 'covid'}, {'truth': 3, 'pred': 'covid'}, {'truth': 4, 'pred': 'covid'}, {'truth': 5, 'pred': 'covid'}, {'truth': 6, 'pred': 'covid'}, {'truth': 7, 'pred': 'covid'}, {'truth': 8, 'pred': 'covid'}, {'truth': 9, 'pred': 'covid'}, {'truth': 10, 'pred': 'covid'}, {'truth': 11, 'pred': 'covid'}, {'truth': 12, 'pred': 'covid'}, {'truth': 13, 'pred': 'covid'}, {'truth': 14, 'pred': 'covid'}, {'truth': 15, 'pred': 'covid'}, {'truth': 16, 'pred': 'covid'}, {'truth': 17, 'pred': 'covid'}, {'truth': 18, 'pred': 'covid'}, {'truth': 19, 'pred': 'covid'}, {'truth': 20, 'pred': 'covid'}, {'truth': 21, 'pred': 'covid'}, {'truth': 22, 'pred': 'covid'}, {'truth': 23, 'pred': 'covid'}, {'truth': 24, 'pred': 'covid'}, {'truth': 25, 'pred': 'covid'}, {'truth': 26, 'pred': 'covid'}, {'truth': 27, 'pred': 'covid'}, {'truth': 28, 'pred': 'covid'}, {'truth': 29, 'pred': 'covid'}, {'truth': 30, 'pred': 'covid'}, {'truth': 31, 'pred': 'covid'}, {'truth': 32, 'pred': 'covid'}, {'truth': 33, 'pred': 'covid'}, {'truth': 34, 'pred': 'covid'}, {'truth': 35, 'pred': 'covid'}, {'truth': 36, 'pred': 'covid'}, {'truth': 37, 'pred': 'covid'}, {'truth': 38, 'pred': 'covid'}, {'truth': 39, 'pred': 'covid'}, {'truth': 40, 'pred': 'covid'}, {'truth': 41, 'pred': 'covid'}, {'truth': 42, 'pred': 'covid'}, {'truth': 43, 'pred': 'covid'}, {'truth': 44, 'pred': 'covid'}, {'truth': 45, 'pred': 'covid'}, {'truth': 46, 'pred': 'covid'}, {'truth': 47, 'pred': 'covid'}, {'truth': 48, 'pred': 'covid'}, {'truth': 49, 'pred': 'covid'}, {'truth': 50, 'pred': 'covid'}, {'truth': 51, 'pred': 'covid'}, {'truth': 52, 'pred': 'covid'}, {'truth': 53, 'pred': 'covid'}, {'truth': 54, 'pred': 'covid'}, {'truth': 55, 'pred': 'covid'}, {'truth': 56, 'pred': 'covid'}, {'truth': 57, 'pred': 'covid'}, {'truth': 58, 'pred': 'covid'}, {'truth': 59, 'pred': 'covid'}, {'truth': 60, 'pred': 'covid'}, {'truth': 61, 'pred': 'covid'}, {'truth': 62, 'pred': 'covid'}, {'truth': 63, 'pred': 'covid'}, {'truth': 64, 'pred': 'covid'}, {'truth': 65, 'pred': 'covid'}, {'truth': 66, 'pred': 'covid'}, {'truth': 67, 'pred': 'covid'}, {'truth': 68, 'pred': 'covid'}, {'truth': 69, 'pred': 'covid'}, {'truth': 70, 'pred': 'covid'}, {'truth': 71, 'pred': 'covid'}, {'truth': 72, 'pred': 'covid'}, {'truth': 73, 'pred': 'covid'}, {'truth': 74, 'pred': 'covid'}, {'truth': 75, 'pred': 'covid'}, {'truth': 76, 'pred': 'covid'}, {'truth': 77, 'pred': 'covid'}, {'truth': 78, 'pred': 'covid'}, {'truth': 79, 'pred': 'covid'}, {'truth': 80, 'pred': 'covid'}, {'truth': 81, 'pred': 'covid'}, {'truth': 82, 'pred': 'covid'}, {'truth': 83, 'pred': 'covid'}, {'truth': 84, 'pred': 'covid'}, {'truth': 85, 'pred': 'covid'}, {'truth': 86, 'pred': 'covid'}, {'truth': 87, 'pred': 'covid'}, {'truth': 88, 'pred': 'covid'}, {'truth': 89, 'pred': 'covid'}, {'truth': 90, 'pred': 'covid'}, {'truth': 91, 'pred': 'covid'}, {'truth': 92, 'pred': 'covid'}, {'truth': 93, 'pred': 'covid'}, {'truth': 94, 'pred': 'covid'}, {'truth': 95, 'pred': 'covid'}, {'truth': 96, 'pred': 'covid'}, {'truth': 97, 'pred': 'covid'}, {'truth': 98, 'pred': 'covid'}, {'truth': 99, 'pred': 'covid'}, {'truth': 100, 'pred': 'covid'}, {'truth': 101, 'pred': 'covid'}, {'truth': 102, 'pred': 'covid'}, {'truth': 103, 'pred': 'covid'}, {'truth': 104, 'pred': 'covid'}, {'truth': 105, 'pred': 'nocovid'}, {'truth': 106, 'pred': 'covid'}, {'truth': 107, 'pred': 'covid'}, {'truth': 108, 'pred': 'covid'}, {'truth': 109, 'pred': 'covid'}, {'truth': 110, 'pred': 'covid'}, {'truth': 111, 'pred': 'covid'}, {'truth': 112, 'pred': 'covid'}, {'truth': 113, 'pred': 'covid'}, {'truth': 114, 'pred': 'covid'}, {'truth': 115, 'pred': 'covid'}, {'truth': 116, 'pred': 'covid'}, {'truth': 117, 'pred': 'covid'}, {'truth': 118, 'pred': 'covid'}, {'truth': 119, 'pred': 'covid'}, {'truth': 120, 'pred': 'covid'}, {'truth': 121, 'pred': 'covid'}, {'truth': 122, 'pred': 'covid'}, {'truth': 123, 'pred': 'covid'}, {'truth': 124, 'pred': 'covid'}, {'truth': 125, 'pred': 'covid'}, {'truth': 126, 'pred': 'covid'}, {'truth': 127, 'pred': 'covid'}, {'truth': 128, 'pred': 'covid'}, {'truth': 129, 'pred': 'covid'}, {'truth': 130, 'pred': 'covid'}, {'truth': 131, 'pred': 'covid'}, {'truth': 132, 'pred': 'nocovid'}, {'truth': 133, 'pred': 'covid'}, {'truth': 134, 'pred': 'covid'}, {'truth': 135, 'pred': 'covid'}, {'truth': 136, 'pred': 'covid'}, {'truth': 137, 'pred': 'covid'}, {'truth': 138, 'pred': 'covid'}, {'truth': 139, 'pred': 'covid'}, {'truth': 140, 'pred': 'covid'}, {'truth': 141, 'pred': 'covid'}, {'truth': 142, 'pred': 'covid'}, {'truth': 143, 'pred': 'covid'}, {'truth': 144, 'pred': 'covid'}, {'truth': 145, 'pred': 'covid'}, {'truth': 146, 'pred': 'covid'}, {'truth': 147, 'pred': 'covid'}, {'truth': 148, 'pred': 'covid'}, {'truth': 149, 'pred': 'covid'}, {'truth': 150, 'pred': 'covid'}, {'truth': 151, 'pred': 'covid'}, {'truth': 152, 'pred': 'covid'}, {'truth': 153, 'pred': 'covid'}, {'truth': 154, 'pred': 'covid'}, {'truth': 155, 'pred': 'covid'}, {'truth': 156, 'pred': 'covid'}, {'truth': 157, 'pred': 'covid'}, {'truth': 158, 'pred': 'covid'}, {'truth': 159, 'pred': 'covid'}, {'truth': 160, 'pred': 'covid'}, {'truth': 161, 'pred': 'covid'}, {'truth': 162, 'pred': 'covid'}, {'truth': 163, 'pred': 'covid'}, {'truth': 164, 'pred': 'covid'}, {'truth': 165, 'pred': 'covid'}, {'truth': 166, 'pred': 'covid'}, {'truth': 167, 'pred': 'covid'}, {'truth': 168, 'pred': 'covid'}, {'truth': 169, 'pred': 'covid'}]\n",
    "[105, 132]\n",
    "2\n",
    "[{'truth': 1, 'pred': 'nocovid'}, {'truth': 2, 'pred': 'nocovid'}, {'truth': 3, 'pred': 'nocovid'}, {'truth': 4, 'pred': 'nocovid'}, {'truth': 5, 'pred': 'nocovid'}, {'truth': 6, 'pred': 'nocovid'}, {'truth': 7, 'pred': 'nocovid'}, {'truth': 8, 'pred': 'nocovid'}, {'truth': 9, 'pred': 'nocovid'}, {'truth': 10, 'pred': 'nocovid'}, {'truth': 11, 'pred': 'nocovid'}, {'truth': 12, 'pred': 'nocovid'}, {'truth': 13, 'pred': 'nocovid'}, {'truth': 14, 'pred': 'nocovid'}, {'truth': 15, 'pred': 'covid'}, {'truth': 16, 'pred': 'nocovid'}, {'truth': 17, 'pred': 'nocovid'}, {'truth': 18, 'pred': 'nocovid'}, {'truth': 19, 'pred': 'nocovid'}, {'truth': 20, 'pred': 'nocovid'}, {'truth': 21, 'pred': 'nocovid'}, {'truth': 22, 'pred': 'nocovid'}, {'truth': 23, 'pred': 'nocovid'}, {'truth': 24, 'pred': 'nocovid'}, {'truth': 25, 'pred': 'nocovid'}, {'truth': 26, 'pred': 'nocovid'}, {'truth': 27, 'pred': 'nocovid'}, {'truth': 28, 'pred': 'nocovid'}, {'truth': 29, 'pred': 'nocovid'}, {'truth': 30, 'pred': 'nocovid'}, {'truth': 31, 'pred': 'nocovid'}, {'truth': 32, 'pred': 'nocovid'}, {'truth': 33, 'pred': 'nocovid'}, {'truth': 34, 'pred': 'nocovid'}, {'truth': 35, 'pred': 'nocovid'}, {'truth': 36, 'pred': 'nocovid'}, {'truth': 37, 'pred': 'nocovid'}, {'truth': 38, 'pred': 'nocovid'}, {'truth': 39, 'pred': 'nocovid'}, {'truth': 40, 'pred': 'covid'}, {'truth': 41, 'pred': 'nocovid'}, {'truth': 42, 'pred': 'nocovid'}, {'truth': 43, 'pred': 'nocovid'}, {'truth': 44, 'pred': 'covid'}, {'truth': 45, 'pred': 'nocovid'}, {'truth': 46, 'pred': 'nocovid'}, {'truth': 47, 'pred': 'nocovid'}, {'truth': 48, 'pred': 'covid'}, {'truth': 49, 'pred': 'nocovid'}, {'truth': 50, 'pred': 'nocovid'}, {'truth': 51, 'pred': 'nocovid'}, {'truth': 52, 'pred': 'nocovid'}, {'truth': 53, 'pred': 'nocovid'}, {'truth': 54, 'pred': 'covid'}, {'truth': 55, 'pred': 'nocovid'}, {'truth': 56, 'pred': 'nocovid'}, {'truth': 57, 'pred': 'covid'}, {'truth': 58, 'pred': 'covid'}, {'truth': 59, 'pred': 'nocovid'}, {'truth': 60, 'pred': 'nocovid'}]\n",
    "[15, 40, 44, 48, 54, 57, 58]\n",
    "7\n",
    "[{'truth': 1, 'pred': 'nocovid'}, {'truth': 2, 'pred': 'nocovid'}, {'truth': 3, 'pred': 'covid'}, {'truth': 4, 'pred': 'nocovid'}, {'truth': 5, 'pred': 'nocovid'}, {'truth': 6, 'pred': 'nocovid'}, {'truth': 7, 'pred': 'nocovid'}, {'truth': 8, 'pred': 'nocovid'}, {'truth': 9, 'pred': 'nocovid'}, {'truth': 10, 'pred': 'nocovid'}, {'truth': 11, 'pred': 'nocovid'}, {'truth': 12, 'pred': 'nocovid'}, {'truth': 13, 'pred': 'nocovid'}, {'truth': 14, 'pred': 'nocovid'}, {'truth': 15, 'pred': 'nocovid'}, {'truth': 16, 'pred': 'nocovid'}, {'truth': 17, 'pred': 'nocovid'}, {'truth': 18, 'pred': 'nocovid'}, {'truth': 19, 'pred': 'nocovid'}, {'truth': 20, 'pred': 'nocovid'}, {'truth': 21, 'pred': 'nocovid'}, {'truth': 22, 'pred': 'nocovid'}, {'truth': 23, 'pred': 'nocovid'}, {'truth': 24, 'pred': 'nocovid'}, {'truth': 25, 'pred': 'nocovid'}, {'truth': 26, 'pred': 'nocovid'}, {'truth': 27, 'pred': 'nocovid'}, {'truth': 28, 'pred': 'nocovid'}, {'truth': 29, 'pred': 'nocovid'}, {'truth': 30, 'pred': 'nocovid'}, {'truth': 31, 'pred': 'nocovid'}, {'truth': 32, 'pred': 'nocovid'}, {'truth': 33, 'pred': 'nocovid'}, {'truth': 34, 'pred': 'nocovid'}, {'truth': 35, 'pred': 'nocovid'}, {'truth': 36, 'pred': 'nocovid'}, {'truth': 37, 'pred': 'nocovid'}, {'truth': 38, 'pred': 'nocovid'}, {'truth': 39, 'pred': 'nocovid'}, {'truth': 40, 'pred': 'nocovid'}, {'truth': 41, 'pred': 'nocovid'}, {'truth': 42, 'pred': 'nocovid'}, {'truth': 43, 'pred': 'nocovid'}, {'truth': 44, 'pred': 'nocovid'}, {'truth': 45, 'pred': 'nocovid'}, {'truth': 46, 'pred': 'nocovid'}, {'truth': 47, 'pred': 'nocovid'}, {'truth': 48, 'pred': 'nocovid'}, {'truth': 49, 'pred': 'nocovid'}, {'truth': 50, 'pred': 'nocovid'}, {'truth': 51, 'pred': 'nocovid'}, {'truth': 52, 'pred': 'nocovid'}, {'truth': 53, 'pred': 'nocovid'}, {'truth': 54, 'pred': 'nocovid'}, {'truth': 55, 'pred': 'nocovid'}, {'truth': 56, 'pred': 'nocovid'}, {'truth': 57, 'pred': 'nocovid'}, {'truth': 58, 'pred': 'nocovid'}, {'truth': 59, 'pred': 'nocovid'}, {'truth': 60, 'pred': 'nocovid'}, {'truth': 61, 'pred': 'nocovid'}, {'truth': 62, 'pred': 'nocovid'}, {'truth': 63, 'pred': 'covid'}, {'truth': 64, 'pred': 'nocovid'}, {'truth': 65, 'pred': 'nocovid'}, {'truth': 66, 'pred': 'nocovid'}, {'truth': 67, 'pred': 'nocovid'}, {'truth': 68, 'pred': 'nocovid'}, {'truth': 69, 'pred': 'nocovid'}, {'truth': 70, 'pred': 'nocovid'}, {'truth': 71, 'pred': 'nocovid'}, {'truth': 72, 'pred': 'nocovid'}, {'truth': 73, 'pred': 'nocovid'}, {'truth': 74, 'pred': 'nocovid'}, {'truth': 75, 'pred': 'nocovid'}, {'truth': 76, 'pred': 'nocovid'}]\n",
    "[3, 63]\n",
    "acc,Sensitivity,Specificity,auc 0.9639344262295082 0.9881656804733728 0.9338235294117647 0.9833362339018448\n",
    "'''\n",
    "\n",
    "'''\n",
    "[{'truth': 1, 'pred': 'covid'}, {'truth': 2, 'pred': 'covid'}, {'truth': 3, 'pred': 'covid'}, {'truth': 4, 'pred': 'covid'}, {'truth': 5, 'pred': 'covid'}, {'truth': 6, 'pred': 'covid'}, {'truth': 7, 'pred': 'covid'}, {'truth': 8, 'pred': 'covid'}, {'truth': 9, 'pred': 'nocovid'}, {'truth': 10, 'pred': 'covid'}, {'truth': 11, 'pred': 'covid'}, {'truth': 12, 'pred': 'covid'}, {'truth': 13, 'pred': 'covid'}, {'truth': 14, 'pred': 'covid'}, {'truth': 15, 'pred': 'covid'}, {'truth': 16, 'pred': 'covid'}, {'truth': 17, 'pred': 'covid'}, {'truth': 18, 'pred': 'covid'}, {'truth': 19, 'pred': 'covid'}, {'truth': 20, 'pred': 'covid'}, {'truth': 21, 'pred': 'covid'}, {'truth': 22, 'pred': 'covid'}, {'truth': 23, 'pred': 'covid'}, {'truth': 24, 'pred': 'covid'}, {'truth': 25, 'pred': 'covid'}, {'truth': 26, 'pred': 'covid'}, {'truth': 27, 'pred': 'covid'}, {'truth': 28, 'pred': 'covid'}, {'truth': 29, 'pred': 'covid'}, {'truth': 30, 'pred': 'covid'}, {'truth': 31, 'pred': 'covid'}, {'truth': 32, 'pred': 'covid'}, {'truth': 33, 'pred': 'covid'}, {'truth': 34, 'pred': 'covid'}, {'truth': 35, 'pred': 'covid'}, {'truth': 36, 'pred': 'covid'}, {'truth': 37, 'pred': 'covid'}, {'truth': 38, 'pred': 'covid'}, {'truth': 39, 'pred': 'covid'}, {'truth': 40, 'pred': 'covid'}, {'truth': 41, 'pred': 'covid'}, {'truth': 42, 'pred': 'covid'}, {'truth': 43, 'pred': 'covid'}, {'truth': 44, 'pred': 'covid'}, {'truth': 45, 'pred': 'covid'}, {'truth': 46, 'pred': 'covid'}, {'truth': 47, 'pred': 'covid'}, {'truth': 48, 'pred': 'covid'}, {'truth': 49, 'pred': 'covid'}, {'truth': 50, 'pred': 'covid'}, {'truth': 51, 'pred': 'covid'}, {'truth': 52, 'pred': 'covid'}, {'truth': 53, 'pred': 'nocovid'}, {'truth': 54, 'pred': 'covid'}, {'truth': 55, 'pred': 'covid'}, {'truth': 56, 'pred': 'covid'}, {'truth': 57, 'pred': 'covid'}, {'truth': 58, 'pred': 'covid'}, {'truth': 59, 'pred': 'covid'}, {'truth': 60, 'pred': 'covid'}, {'truth': 61, 'pred': 'covid'}, {'truth': 62, 'pred': 'nocovid'}, {'truth': 63, 'pred': 'covid'}, {'truth': 64, 'pred': 'covid'}, {'truth': 65, 'pred': 'covid'}, {'truth': 66, 'pred': 'covid'}, {'truth': 67, 'pred': 'covid'}, {'truth': 68, 'pred': 'covid'}, {'truth': 69, 'pred': 'covid'}, {'truth': 70, 'pred': 'covid'}, {'truth': 71, 'pred': 'covid'}, {'truth': 72, 'pred': 'covid'}, {'truth': 73, 'pred': 'covid'}, {'truth': 74, 'pred': 'covid'}, {'truth': 75, 'pred': 'covid'}, {'truth': 76, 'pred': 'covid'}, {'truth': 77, 'pred': 'covid'}, {'truth': 78, 'pred': 'covid'}, {'truth': 79, 'pred': 'covid'}, {'truth': 80, 'pred': 'covid'}, {'truth': 81, 'pred': 'covid'}, {'truth': 82, 'pred': 'covid'}, {'truth': 83, 'pred': 'covid'}, {'truth': 84, 'pred': 'covid'}, {'truth': 85, 'pred': 'covid'}, {'truth': 86, 'pred': 'covid'}, {'truth': 87, 'pred': 'covid'}, {'truth': 88, 'pred': 'covid'}, {'truth': 89, 'pred': 'covid'}, {'truth': 90, 'pred': 'covid'}, {'truth': 91, 'pred': 'covid'}, {'truth': 92, 'pred': 'covid'}, {'truth': 93, 'pred': 'covid'}, {'truth': 94, 'pred': 'covid'}, {'truth': 95, 'pred': 'covid'}, {'truth': 96, 'pred': 'covid'}, {'truth': 97, 'pred': 'covid'}, {'truth': 98, 'pred': 'covid'}, {'truth': 99, 'pred': 'covid'}, {'truth': 100, 'pred': 'covid'}, {'truth': 101, 'pred': 'covid'}, {'truth': 102, 'pred': 'covid'}, {'truth': 103, 'pred': 'nocovid'}, {'truth': 104, 'pred': 'covid'}, {'truth': 105, 'pred': 'nocovid'}, {'truth': 106, 'pred': 'covid'}, {'truth': 107, 'pred': 'covid'}, {'truth': 108, 'pred': 'covid'}, {'truth': 109, 'pred': 'covid'}, {'truth': 110, 'pred': 'covid'}, {'truth': 111, 'pred': 'covid'}, {'truth': 112, 'pred': 'covid'}, {'truth': 113, 'pred': 'covid'}, {'truth': 114, 'pred': 'covid'}, {'truth': 115, 'pred': 'covid'}, {'truth': 116, 'pred': 'covid'}, {'truth': 117, 'pred': 'covid'}, {'truth': 118, 'pred': 'covid'}, {'truth': 119, 'pred': 'covid'}, {'truth': 120, 'pred': 'covid'}, {'truth': 121, 'pred': 'covid'}, {'truth': 122, 'pred': 'covid'}, {'truth': 123, 'pred': 'covid'}, {'truth': 124, 'pred': 'covid'}, {'truth': 125, 'pred': 'covid'}, {'truth': 126, 'pred': 'covid'}, {'truth': 127, 'pred': 'covid'}, {'truth': 128, 'pred': 'covid'}, {'truth': 129, 'pred': 'covid'}, {'truth': 130, 'pred': 'covid'}, {'truth': 131, 'pred': 'covid'}, {'truth': 132, 'pred': 'covid'}, {'truth': 133, 'pred': 'covid'}, {'truth': 134, 'pred': 'covid'}, {'truth': 135, 'pred': 'covid'}, {'truth': 136, 'pred': 'covid'}, {'truth': 137, 'pred': 'covid'}, {'truth': 138, 'pred': 'covid'}, {'truth': 139, 'pred': 'covid'}, {'truth': 140, 'pred': 'covid'}, {'truth': 141, 'pred': 'covid'}, {'truth': 142, 'pred': 'covid'}, {'truth': 143, 'pred': 'covid'}, {'truth': 144, 'pred': 'covid'}, {'truth': 145, 'pred': 'covid'}, {'truth': 146, 'pred': 'covid'}, {'truth': 147, 'pred': 'covid'}, {'truth': 148, 'pred': 'covid'}, {'truth': 149, 'pred': 'covid'}, {'truth': 150, 'pred': 'covid'}, {'truth': 151, 'pred': 'covid'}, {'truth': 152, 'pred': 'covid'}, {'truth': 153, 'pred': 'covid'}, {'truth': 154, 'pred': 'covid'}, {'truth': 155, 'pred': 'covid'}, {'truth': 156, 'pred': 'covid'}, {'truth': 157, 'pred': 'covid'}, {'truth': 158, 'pred': 'covid'}, {'truth': 159, 'pred': 'covid'}, {'truth': 160, 'pred': 'covid'}, {'truth': 161, 'pred': 'covid'}, {'truth': 162, 'pred': 'covid'}, {'truth': 163, 'pred': 'covid'}, {'truth': 164, 'pred': 'covid'}, {'truth': 165, 'pred': 'covid'}, {'truth': 166, 'pred': 'covid'}, {'truth': 167, 'pred': 'covid'}, {'truth': 168, 'pred': 'covid'}, {'truth': 169, 'pred': 'covid'}]\n",
    "[9, 53, 62, 103, 105]\n",
    "5\n",
    "[{'truth': 1, 'pred': 'nocovid'}, {'truth': 2, 'pred': 'nocovid'}, {'truth': 3, 'pred': 'nocovid'}, {'truth': 4, 'pred': 'nocovid'}, {'truth': 5, 'pred': 'nocovid'}, {'truth': 6, 'pred': 'nocovid'}, {'truth': 7, 'pred': 'nocovid'}, {'truth': 8, 'pred': 'nocovid'}, {'truth': 9, 'pred': 'nocovid'}, {'truth': 10, 'pred': 'nocovid'}, {'truth': 11, 'pred': 'nocovid'}, {'truth': 12, 'pred': 'nocovid'}, {'truth': 13, 'pred': 'nocovid'}, {'truth': 14, 'pred': 'nocovid'}, {'truth': 15, 'pred': 'nocovid'}, {'truth': 16, 'pred': 'nocovid'}, {'truth': 17, 'pred': 'nocovid'}, {'truth': 18, 'pred': 'nocovid'}, {'truth': 19, 'pred': 'nocovid'}, {'truth': 20, 'pred': 'nocovid'}, {'truth': 21, 'pred': 'nocovid'}, {'truth': 22, 'pred': 'nocovid'}, {'truth': 23, 'pred': 'nocovid'}, {'truth': 24, 'pred': 'nocovid'}, {'truth': 25, 'pred': 'nocovid'}, {'truth': 26, 'pred': 'nocovid'}, {'truth': 27, 'pred': 'nocovid'}, {'truth': 28, 'pred': 'nocovid'}, {'truth': 29, 'pred': 'nocovid'}, {'truth': 30, 'pred': 'nocovid'}, {'truth': 31, 'pred': 'nocovid'}, {'truth': 32, 'pred': 'nocovid'}, {'truth': 33, 'pred': 'nocovid'}, {'truth': 34, 'pred': 'nocovid'}, {'truth': 35, 'pred': 'nocovid'}, {'truth': 36, 'pred': 'nocovid'}, {'truth': 37, 'pred': 'nocovid'}, {'truth': 38, 'pred': 'nocovid'}, {'truth': 39, 'pred': 'nocovid'}, {'truth': 40, 'pred': 'nocovid'}, {'truth': 41, 'pred': 'nocovid'}, {'truth': 42, 'pred': 'nocovid'}, {'truth': 43, 'pred': 'nocovid'}, {'truth': 44, 'pred': 'nocovid'}, {'truth': 45, 'pred': 'nocovid'}, {'truth': 46, 'pred': 'nocovid'}, {'truth': 47, 'pred': 'nocovid'}, {'truth': 48, 'pred': 'nocovid'}, {'truth': 49, 'pred': 'nocovid'}, {'truth': 50, 'pred': 'nocovid'}, {'truth': 51, 'pred': 'nocovid'}, {'truth': 52, 'pred': 'nocovid'}, {'truth': 53, 'pred': 'nocovid'}, {'truth': 54, 'pred': 'covid'}, {'truth': 55, 'pred': 'nocovid'}, {'truth': 56, 'pred': 'nocovid'}, {'truth': 57, 'pred': 'covid'}, {'truth': 58, 'pred': 'nocovid'}, {'truth': 59, 'pred': 'nocovid'}, {'truth': 60, 'pred': 'nocovid'}]\n",
    "[54, 57]\n",
    "2\n",
    "[{'truth': 1, 'pred': 'nocovid'}, {'truth': 2, 'pred': 'nocovid'}, {'truth': 3, 'pred': 'nocovid'}, {'truth': 4, 'pred': 'nocovid'}, {'truth': 5, 'pred': 'nocovid'}, {'truth': 6, 'pred': 'nocovid'}, {'truth': 7, 'pred': 'nocovid'}, {'truth': 8, 'pred': 'nocovid'}, {'truth': 9, 'pred': 'nocovid'}, {'truth': 10, 'pred': 'nocovid'}, {'truth': 11, 'pred': 'nocovid'}, {'truth': 12, 'pred': 'nocovid'}, {'truth': 13, 'pred': 'nocovid'}, {'truth': 14, 'pred': 'nocovid'}, {'truth': 15, 'pred': 'nocovid'}, {'truth': 16, 'pred': 'nocovid'}, {'truth': 17, 'pred': 'nocovid'}, {'truth': 18, 'pred': 'nocovid'}, {'truth': 19, 'pred': 'nocovid'}, {'truth': 20, 'pred': 'nocovid'}, {'truth': 21, 'pred': 'nocovid'}, {'truth': 22, 'pred': 'nocovid'}, {'truth': 23, 'pred': 'nocovid'}, {'truth': 24, 'pred': 'nocovid'}, {'truth': 25, 'pred': 'nocovid'}, {'truth': 26, 'pred': 'nocovid'}, {'truth': 27, 'pred': 'nocovid'}, {'truth': 28, 'pred': 'nocovid'}, {'truth': 29, 'pred': 'nocovid'}, {'truth': 30, 'pred': 'nocovid'}, {'truth': 31, 'pred': 'nocovid'}, {'truth': 32, 'pred': 'nocovid'}, {'truth': 33, 'pred': 'nocovid'}, {'truth': 34, 'pred': 'nocovid'}, {'truth': 35, 'pred': 'nocovid'}, {'truth': 36, 'pred': 'nocovid'}, {'truth': 37, 'pred': 'nocovid'}, {'truth': 38, 'pred': 'nocovid'}, {'truth': 39, 'pred': 'nocovid'}, {'truth': 40, 'pred': 'nocovid'}, {'truth': 41, 'pred': 'nocovid'}, {'truth': 42, 'pred': 'nocovid'}, {'truth': 43, 'pred': 'nocovid'}, {'truth': 44, 'pred': 'nocovid'}, {'truth': 45, 'pred': 'nocovid'}, {'truth': 46, 'pred': 'nocovid'}, {'truth': 47, 'pred': 'nocovid'}, {'truth': 48, 'pred': 'nocovid'}, {'truth': 49, 'pred': 'nocovid'}, {'truth': 50, 'pred': 'nocovid'}, {'truth': 51, 'pred': 'nocovid'}, {'truth': 52, 'pred': 'nocovid'}, {'truth': 53, 'pred': 'nocovid'}, {'truth': 54, 'pred': 'nocovid'}, {'truth': 55, 'pred': 'nocovid'}, {'truth': 56, 'pred': 'nocovid'}, {'truth': 57, 'pred': 'nocovid'}, {'truth': 58, 'pred': 'nocovid'}, {'truth': 59, 'pred': 'nocovid'}, {'truth': 60, 'pred': 'nocovid'}, {'truth': 61, 'pred': 'nocovid'}, {'truth': 62, 'pred': 'nocovid'}, {'truth': 63, 'pred': 'nocovid'}, {'truth': 64, 'pred': 'nocovid'}, {'truth': 65, 'pred': 'nocovid'}, {'truth': 66, 'pred': 'nocovid'}, {'truth': 67, 'pred': 'nocovid'}, {'truth': 68, 'pred': 'nocovid'}, {'truth': 69, 'pred': 'nocovid'}, {'truth': 70, 'pred': 'nocovid'}, {'truth': 71, 'pred': 'nocovid'}, {'truth': 72, 'pred': 'nocovid'}, {'truth': 73, 'pred': 'nocovid'}, {'truth': 74, 'pred': 'nocovid'}, {'truth': 75, 'pred': 'nocovid'}, {'truth': 76, 'pred': 'nocovid'}]\n",
    "[]\n",
    "acc,Sensitivity,Specificity,auc 0.9770491803278688 0.9704142011834319 0.9852941176470589 0.9943873999303863\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7790154-6370-4ef8-b2cf-26da02343d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "import numpy\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "from keras import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers import *\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.tests.test_base import K\n",
    "from tensorflow import expand_dims\n",
    "\n",
    "from keras import optimizers\n",
    "input_tensor = Input(shape=(32,16))\n",
    "x2 = Flatten()(input_tensor)\n",
    "x2 = Dense(256,activation = 'relu')(x2)\n",
    "x2 = Dense(128,activation = 'relu')(x2)\n",
    "x2 = Dense(32,activation = 'relu')(x2)\n",
    "out2 = Dense(2, activation = 'softmax')(x2)\n",
    "model2 = Model(input_tensor,out2)\n",
    "# opt = optimizers.Adam(lr=0.001)\n",
    "# model2.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=['accuracy'])\n",
    "model2.load_weights('mean621_108_noweight_model.h5')\n",
    "import numpy\n",
    "covid = [0., 1]\n",
    "covid = numpy.array(covid)\n",
    "nocovid = [1, 0.]\n",
    "nocovid = numpy.array(nocovid)\n",
    "x_test = numpy.zeros((305,32,16))\n",
    "\n",
    "x_train = numpy.zeros((1,32,16))\n",
    "cap_pred = np.ones(shape=(305,2))\n",
    "cap_true = np.ones(shape=(305,2))\n",
    "covid=0\n",
    "nocovid=0\n",
    "cap=0\n",
    "nocap=0\n",
    "normal=0\n",
    "nonormal=0\n",
    "\n",
    "y_test = numpy.zeros((305,2))\n",
    "for i in range(1,170):\n",
    "    test = np.ones(shape=(108, 32, 16))\n",
    "    test = np.load(\"../autodl-tmp/capsule1083216/covid/covidmap\"+str(i)+\".npy\")\n",
    "    y1 = numpy.max(test,0)\n",
    "    y2 =numpy.mean(test,0)\n",
    "    y3 = 0.5*(y1+y2)\n",
    "    x_train[0]=y3\n",
    "    cap_pred[i-1] = model2.predict(x_train)\n",
    "    cap_true[i-1] = [0,1]\n",
    "    if cap_pred[i-1][1]>0.5:\n",
    "        covid+=1\n",
    "    else:nocovid+=1\n",
    "    x_test[i-1] = y3\n",
    "    y_test[i-1] = covid\n",
    "    print(i-1)\n",
    "for i in range(1,77):\n",
    "    test = np.ones(shape=(108, 32, 16))\n",
    "    test = np.load(\"../autodl-tmp/capsule1083216/normal/normalmap\"+str(i)+\".npy\")\n",
    "    y1 = numpy.max(test,0)\n",
    "    y2 =numpy.mean(test,0)\n",
    "    y3 = 0.5*(y1+y2)\n",
    "    x_train[0]=y3\n",
    "    cap_pred[i+168] = model2.predict(x_train)\n",
    "    cap_true[i+168] = [1,0]\n",
    "    if cap_pred[i-1][1]>0.5:\n",
    "        nonormal+=1\n",
    "    else:normal+=1\n",
    "    x_test[i+168] = y3\n",
    "    y_test[i+168] = nocovid\n",
    "    print(i+168)\n",
    "for i in range(1,61):\n",
    "    test = np.ones(shape=(108, 32, 16))\n",
    "    test = np.load(\"../autodl-tmp/capsule1083216/cap/capmap\"+str(i)+\".npy\")\n",
    "    y1 = numpy.max(test,0)\n",
    "    y2 =numpy.mean(test,0)\n",
    "    y3 = 0.5*(y1+y2)\n",
    "    x_train[0]=y3\n",
    "    cap_pred[i+244] = model2.predict(x_train)\n",
    "    cap_true[i+244] = [1,0]\n",
    "    if cap_pred[i-1][1]>0.5:\n",
    "        nocap+=1\n",
    "    else:cap+=1\n",
    "print(nocovid,nocap,nonormal)\n",
    "acc = (305-nocap-nonormal-nocovid)/305\n",
    "\n",
    "Sensitivity = 1-(nocovid/169)\n",
    "\n",
    "Specificity = 1 - (nocap+nonormal)/136\n",
    "import numpy as np\n",
    "# from sklearn import metrics\n",
    "auc = roc_auc_score(cap_true,cap_pred)\n",
    "print(\"acc,Sensitivity,Specificity,auc\",acc,Sensitivity,Specificity,auc)\n",
    "\n",
    "    # x_test[i+244] = y3\n",
    "    # y_test[i+244] = nocovid\n",
    "    # print(i+244)\n",
    "# batch_size=16\n",
    "# epochs=5\n",
    "# history = model2.fit(\n",
    "#         [x_test], [y_test],\n",
    "#         batch_size=batch_size,\n",
    "#         epochs=epochs,\n",
    "#         shuffle=True,\n",
    "#         validation_data= ([x_test],[y_test]),\n",
    "#         # validation_split=0.2,\n",
    "#     #validation_split=0.2,\n",
    "#     verbose=0\n",
    "# )\n",
    "# mp = \"../autodl-tmp/maxmean_model2.h5\" #max16 0.885\n",
    "# model2.save(mp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f56559c-7237-4178-a657-9fd01dc2874b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 56 70\n"
     ]
    }
   ],
   "source": [
    "#acc,Sensitivity,Specificity,auc 0.5442622950819672 0.9289940828402367 0.06617647058823528 0.9397841977027497\n",
    "print(nocovid,nocap,nonormal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb2fb10-4055-42c4-bc85-88886637f1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mobile = tf.keras.applications.MobileNetV2(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n",
    "path='../autodl-tmp/lung/covid/covid1.npy'\n",
    "x = numpy.load(path)\n",
    "c = mobile.predict(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python]",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
